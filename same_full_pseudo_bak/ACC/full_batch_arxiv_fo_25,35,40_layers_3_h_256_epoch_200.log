main start at this time 1648617900.429341
ogbn-arxiv
# Nodes: 169343
# Edges: 2315598
# Train: 90941
# Val: 29799
# Test: 48603
# Classes: 40

in feats:  128
 full batch blocks save
Number of first layer input nodes during this epoch:  167730
torch.Size([167730, 128])
torch.Size([166638, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.035057783126831055 |0.45464277267456055 |0.8226213455200195 |0.000316619873046875 |0.2219095230102539 |0.007992744445800781 |
----------------------------------------------------------pseudo_mini_loss sum 5.540483474731445
Run 00 | Epoch 00000 | Loss 5.5405 | Train 0.1658 | Val 0.0889 | Test 0.0695
Number of nodes for computation during this epoch:  491691
Number of first layer input nodes during this epoch:  167730
 full batch blocks save
Number of first layer input nodes during this epoch:  167677
torch.Size([167677, 128])
torch.Size([166623, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.06054568290710449 |0.04566550254821777 |0.007936716079711914 |0.00023889541625976562 |0.00466465950012207 |0.004153251647949219 |
----------------------------------------------------------pseudo_mini_loss sum 5.145788192749023
Total dataloading + training time/epoch 2.094264268875122
Training time/epoch 2.094107151031494
Training time without block to device /epoch 2.0484416484832764
Training time without total dataloading part /epoch 0.01699352264404297
load block tensor time/epoch 0.06054568290710449
block to device time/epoch 0.04566550254821777
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00001 | Loss 5.1458 | Train 0.2035 | Val 0.1387 | Test 0.1185
Number of nodes for computation during this epoch:  491621
Number of first layer input nodes during this epoch:  167677
 full batch blocks save
Number of first layer input nodes during this epoch:  167748
torch.Size([167748, 128])
torch.Size([166681, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.04824662208557129 |0.03764653205871582 |0.08976221084594727 |0.00018095970153808594 |0.22246837615966797 |0.0023775100708007812 |
----------------------------------------------------------pseudo_mini_loss sum 4.809394836425781
Total dataloading + training time/epoch 2.0582739114761353
Training time/epoch 2.0220987796783447
Training time without block to device /epoch 1.984452247619629
Training time without total dataloading part /epoch 0.3147890567779541
load block tensor time/epoch 0.04824662208557129
block to device time/epoch 0.03764653205871582
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00002 | Loss 4.8094 | Train 0.2323 | Val 0.1998 | Test 0.1764
Number of nodes for computation during this epoch:  491763
Number of first layer input nodes during this epoch:  167748
 full batch blocks save
Number of first layer input nodes during this epoch:  167707
torch.Size([167707, 128])
torch.Size([166648, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.03191423416137695 |0.02379631996154785 |0.007753849029541016 |0.00024580955505371094 |0.004415273666381836 |0.0035359859466552734 |
----------------------------------------------------------pseudo_mini_loss sum 4.4526872634887695
Total dataloading + training time/epoch 1.9995179971059163
Training time/epoch 1.8818562030792236
Training time without block to device /epoch 1.8580598831176758
Training time without total dataloading part /epoch 0.015950918197631836
load block tensor time/epoch 0.03191423416137695
block to device time/epoch 0.02379631996154785
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00003 | Loss 4.4527 | Train 0.2518 | Val 0.2458 | Test 0.2196
Number of nodes for computation during this epoch:  491637
Number of first layer input nodes during this epoch:  167707
 full batch blocks save
Number of first layer input nodes during this epoch:  167725
torch.Size([167725, 128])
torch.Size([166642, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.037027597427368164 |0.018270015716552734 |0.007798671722412109 |0.00022530555725097656 |0.004438877105712891 |0.003527402877807617 |
----------------------------------------------------------pseudo_mini_loss sum 4.159562587738037
Total dataloading + training time/epoch 1.9643823504447937
Training time/epoch 1.8588225841522217
Training time without block to device /epoch 1.840552568435669
Training time without total dataloading part /epoch 0.015990257263183594
load block tensor time/epoch 0.037027597427368164
block to device time/epoch 0.018270015716552734
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00004 | Loss 4.1596 | Train 0.2631 | Val 0.2693 | Test 0.2435
Number of nodes for computation during this epoch:  491686
Number of first layer input nodes during this epoch:  167725
 full batch blocks save
Number of first layer input nodes during this epoch:  167765
torch.Size([167765, 128])
torch.Size([166693, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.040712833404541016 |0.0194091796875 |0.007870674133300781 |0.00022912025451660156 |0.3020296096801758 |0.004019021987915039 |
----------------------------------------------------------pseudo_mini_loss sum 3.8763129711151123
Total dataloading + training time/epoch 1.9557411193847656
Training time/epoch 1.9210071563720703
Training time without block to device /epoch 1.9015979766845703
Training time without total dataloading part /epoch 0.3141484260559082
load block tensor time/epoch 0.040712833404541016
block to device time/epoch 0.0194091796875
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00005 | Loss 3.8763 | Train 0.2685 | Val 0.2818 | Test 0.2554
Number of nodes for computation during this epoch:  491794
Number of first layer input nodes during this epoch:  167765
 full batch blocks save
Number of first layer input nodes during this epoch:  167778
torch.Size([167778, 128])
torch.Size([166727, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.045920610427856445 |0.016961336135864258 |0.09169983863830566 |0.00017189979553222656 |0.21996092796325684 |0.002347707748413086 |
----------------------------------------------------------pseudo_mini_loss sum 3.6491808891296387
Total dataloading + training time/epoch 1.961492935816447
Training time/epoch 1.990098476409912
Training time without block to device /epoch 1.9731371402740479
Training time without total dataloading part /epoch 0.3141803741455078
load block tensor time/epoch 0.045920610427856445
block to device time/epoch 0.016961336135864258
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00006 | Loss 3.6492 | Train 0.2722 | Val 0.2892 | Test 0.2620
Number of nodes for computation during this epoch:  491920
Number of first layer input nodes during this epoch:  167778
 full batch blocks save
Number of first layer input nodes during this epoch:  167731
torch.Size([167731, 128])
torch.Size([166669, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.04860496520996094 |0.017399072647094727 |0.007826089859008789 |0.00022840499877929688 |0.004214763641357422 |0.003498077392578125 |
----------------------------------------------------------pseudo_mini_loss sum 3.441239356994629
Total dataloading + training time/epoch 1.9540307181222099
Training time/epoch 1.909104824066162
Training time without block to device /epoch 1.8917057514190674
Training time without total dataloading part /epoch 0.015767335891723633
load block tensor time/epoch 0.04860496520996094
block to device time/epoch 0.017399072647094727
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00007 | Loss 3.4412 | Train 0.2747 | Val 0.2944 | Test 0.2664
Number of nodes for computation during this epoch:  491685
Number of first layer input nodes during this epoch:  167731
 full batch blocks save
Number of first layer input nodes during this epoch:  167736
torch.Size([167736, 128])
torch.Size([166670, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.022519588470458984 |0.01905536651611328 |0.008304119110107422 |0.00022363662719726562 |0.004329204559326172 |0.00461125373840332 |
----------------------------------------------------------pseudo_mini_loss sum 3.28240966796875
Total dataloading + training time/epoch 1.9490773379802704
Training time/epoch 1.9142522811889648
Training time without block to device /epoch 1.8951969146728516
Training time without total dataloading part /epoch 0.01746821403503418
load block tensor time/epoch 0.022519588470458984
block to device time/epoch 0.01905536651611328
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00008 | Loss 3.2824 | Train 0.2774 | Val 0.2998 | Test 0.2719
Number of nodes for computation during this epoch:  491713
Number of first layer input nodes during this epoch:  167736
 full batch blocks save
Number of first layer input nodes during this epoch:  167756
torch.Size([167756, 128])
torch.Size([166667, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.0612797737121582 |0.03421139717102051 |0.0069501399993896484 |0.0002002716064453125 |0.0038704872131347656 |0.002981901168823242 |
----------------------------------------------------------pseudo_mini_loss sum 3.1367266178131104
Total dataloading + training time/epoch 1.9556528727213542
Training time/epoch 2.0080902576446533
Training time without block to device /epoch 1.9738788604736328
Training time without total dataloading part /epoch 0.014002799987792969
load block tensor time/epoch 0.0612797737121582
block to device time/epoch 0.03421139717102051
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00009 | Loss 3.1367 | Train 0.2820 | Val 0.3062 | Test 0.2796
Number of nodes for computation during this epoch:  491807
Number of first layer input nodes during this epoch:  167756
 full batch blocks save
Number of first layer input nodes during this epoch:  167752
torch.Size([167752, 128])
torch.Size([166686, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.030931949615478516 |0.01760268211364746 |0.008084535598754883 |0.00023102760314941406 |0.00443267822265625 |0.0037174224853515625 |
----------------------------------------------------------pseudo_mini_loss sum 3.015740394592285
Total dataloading + training time/epoch 1.9458234071731568
Training time/epoch 1.8572688102722168
Training time without block to device /epoch 1.8396661281585693
Training time without total dataloading part /epoch 0.01646566390991211
load block tensor time/epoch 0.030931949615478516
block to device time/epoch 0.01760268211364746
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00010 | Loss 3.0157 | Train 0.2879 | Val 0.3143 | Test 0.2917
Number of nodes for computation during this epoch:  491795
Number of first layer input nodes during this epoch:  167752
 full batch blocks save
Number of first layer input nodes during this epoch:  167753
torch.Size([167753, 128])
torch.Size([166693, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.04775404930114746 |0.016819477081298828 |0.008682727813720703 |0.0002601146697998047 |0.004445552825927734 |0.004671335220336914 |
----------------------------------------------------------pseudo_mini_loss sum 2.8930742740631104
Total dataloading + training time/epoch 1.9511908184398303
Training time/epoch 2.004714012145996
Training time without block to device /epoch 1.9878945350646973
Training time without total dataloading part /epoch 0.018059730529785156
load block tensor time/epoch 0.04775404930114746
block to device time/epoch 0.016819477081298828
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00011 | Loss 2.8931 | Train 0.2950 | Val 0.3265 | Test 0.3086
Number of nodes for computation during this epoch:  491760
Number of first layer input nodes during this epoch:  167753
 full batch blocks save
Number of first layer input nodes during this epoch:  167725
torch.Size([167725, 128])
torch.Size([166640, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.046449899673461914 |0.01730966567993164 |0.009092569351196289 |0.0002810955047607422 |0.0044214725494384766 |0.0047304630279541016 |
----------------------------------------------------------pseudo_mini_loss sum 2.7962841987609863
Total dataloading + training time/epoch 1.9516698320706685
Training time/epoch 1.956775426864624
Training time without block to device /epoch 1.9394657611846924
Training time without total dataloading part /epoch 0.01852560043334961
load block tensor time/epoch 0.046449899673461914
block to device time/epoch 0.01730966567993164
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00012 | Loss 2.7963 | Train 0.3039 | Val 0.3401 | Test 0.3303
Number of nodes for computation during this epoch:  491704
Number of first layer input nodes during this epoch:  167725
 full batch blocks save
Number of first layer input nodes during this epoch:  167758
torch.Size([167758, 128])
torch.Size([166686, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.028415918350219727 |0.04124259948730469 |0.008619308471679688 |0.00026416778564453125 |0.004449367523193359 |0.004758119583129883 |
----------------------------------------------------------pseudo_mini_loss sum 2.7120120525360107
Total dataloading + training time/epoch 1.9466615273402288
Training time/epoch 1.8864076137542725
Training time without block to device /epoch 1.8451650142669678
Training time without total dataloading part /epoch 0.01809096336364746
load block tensor time/epoch 0.028415918350219727
block to device time/epoch 0.04124259948730469
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00013 | Loss 2.7120 | Train 0.3135 | Val 0.3554 | Test 0.3535
Number of nodes for computation during this epoch:  491824
Number of first layer input nodes during this epoch:  167758
 full batch blocks save
Number of first layer input nodes during this epoch:  167738
torch.Size([167738, 128])
torch.Size([166663, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.03873634338378906 |0.01674485206604004 |0.008547544479370117 |0.00022983551025390625 |0.004320859909057617 |0.004614114761352539 |
----------------------------------------------------------pseudo_mini_loss sum 2.6339027881622314
Total dataloading + training time/epoch 1.9424969809395927
Training time/epoch 1.8882026672363281
Training time without block to device /epoch 1.871457815170288
Training time without total dataloading part /epoch 0.01771235466003418
load block tensor time/epoch 0.03873634338378906
block to device time/epoch 0.01674485206604004
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00014 | Loss 2.6339 | Train 0.3223 | Val 0.3705 | Test 0.3794
Number of nodes for computation during this epoch:  491718
Number of first layer input nodes during this epoch:  167738
 full batch blocks save
Number of first layer input nodes during this epoch:  167730
torch.Size([167730, 128])
torch.Size([166657, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.0210113525390625 |0.018970489501953125 |0.009788990020751953 |0.00027823448181152344 |0.004379987716674805 |0.005196094512939453 |
----------------------------------------------------------pseudo_mini_loss sum 2.555264472961426
Total dataloading + training time/epoch 1.9363949298858643
Training time/epoch 1.850874662399292
Training time without block to device /epoch 1.8319041728973389
Training time without total dataloading part /epoch 0.019643306732177734
load block tensor time/epoch 0.0210113525390625
block to device time/epoch 0.018970489501953125
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00015 | Loss 2.5553 | Train 0.3298 | Val 0.3872 | Test 0.4035
Number of nodes for computation during this epoch:  491714
Number of first layer input nodes during this epoch:  167730
 full batch blocks save
Number of first layer input nodes during this epoch:  167756
torch.Size([167756, 128])
torch.Size([166722, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.03628373146057129 |0.017774343490600586 |0.00897359848022461 |0.00023937225341796875 |0.004248857498168945 |0.00478816032409668 |
----------------------------------------------------------pseudo_mini_loss sum 2.4939754009246826
Total dataloading + training time/epoch 1.9298253059387207
Training time/epoch 1.8311257362365723
Training time without block to device /epoch 1.8133513927459717
Training time without total dataloading part /epoch 0.018249988555908203
load block tensor time/epoch 0.03628373146057129
block to device time/epoch 0.017774343490600586
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00016 | Loss 2.4940 | Train 0.3357 | Val 0.3999 | Test 0.4227
Number of nodes for computation during this epoch:  491843
Number of first layer input nodes during this epoch:  167756
 full batch blocks save
Number of first layer input nodes during this epoch:  167725
torch.Size([167725, 128])
torch.Size([166641, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.029903888702392578 |0.017367124557495117 |0.008780241012573242 |0.000263214111328125 |0.004316806793212891 |0.004864692687988281 |
----------------------------------------------------------pseudo_mini_loss sum 2.4285926818847656
Total dataloading + training time/epoch 1.9253150435055004
Training time/epoch 1.8529961109161377
Training time without block to device /epoch 1.8356289863586426
Training time without total dataloading part /epoch 0.01822495460510254
load block tensor time/epoch 0.029903888702392578
block to device time/epoch 0.017367124557495117
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00017 | Loss 2.4286 | Train 0.3393 | Val 0.4057 | Test 0.4352
Number of nodes for computation during this epoch:  491705
Number of first layer input nodes during this epoch:  167725
 full batch blocks save
Number of first layer input nodes during this epoch:  167721
torch.Size([167721, 128])
torch.Size([166635, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.03671145439147949 |0.027872085571289062 |0.008735179901123047 |0.00023174285888671875 |0.004199504852294922 |0.004465818405151367 |
----------------------------------------------------------pseudo_mini_loss sum 2.3781204223632812
Total dataloading + training time/epoch 1.9229608641730414
Training time/epoch 1.8827860355377197
Training time without block to device /epoch 1.8549139499664307
Training time without total dataloading part /epoch 0.017632246017456055
load block tensor time/epoch 0.03671145439147949
block to device time/epoch 0.027872085571289062
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00018 | Loss 2.3781 | Train 0.3406 | Val 0.4073 | Test 0.4389
Number of nodes for computation during this epoch:  491670
Number of first layer input nodes during this epoch:  167721
 full batch blocks save
Number of first layer input nodes during this epoch:  167777
torch.Size([167777, 128])
torch.Size([166693, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.03786015510559082 |0.018102645874023438 |0.008769035339355469 |0.00023555755615234375 |0.00443577766418457 |0.004757881164550781 |
----------------------------------------------------------pseudo_mini_loss sum 2.3228237628936768
Total dataloading + training time/epoch 1.9203240620462518
Training time/epoch 1.8727071285247803
Training time without block to device /epoch 1.8546044826507568
Training time without total dataloading part /epoch 0.018198251724243164
load block tensor time/epoch 0.03786015510559082
block to device time/epoch 0.018102645874023438
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00019 | Loss 2.3228 | Train 0.3394 | Val 0.4021 | Test 0.4374
Number of nodes for computation during this epoch:  491801
Number of first layer input nodes during this epoch:  167777
 full batch blocks save
Number of first layer input nodes during this epoch:  167743
torch.Size([167743, 128])
torch.Size([166665, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.020768404006958008 |0.01726055145263672 |0.009218931198120117 |0.0002789497375488281 |0.004395246505737305 |0.005028963088989258 |
----------------------------------------------------------pseudo_mini_loss sum 2.2794294357299805
Total dataloading + training time/epoch 1.9149539828300477
Training time/epoch 1.812817096710205
Training time without block to device /epoch 1.7955565452575684
Training time without total dataloading part /epoch 0.018922090530395508
load block tensor time/epoch 0.020768404006958008
block to device time/epoch 0.01726055145263672
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00020 | Loss 2.2794 | Train 0.3370 | Val 0.3952 | Test 0.4336
Number of nodes for computation during this epoch:  491706
Number of first layer input nodes during this epoch:  167743
 full batch blocks save
Number of first layer input nodes during this epoch:  167734
torch.Size([167734, 128])
torch.Size([166689, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.022920846939086914 |0.019181251525878906 |0.008832454681396484 |0.00024509429931640625 |0.004064083099365234 |0.004761695861816406 |
----------------------------------------------------------pseudo_mini_loss sum 2.23502254486084
Total dataloading + training time/epoch 1.9147876784915017
Training time/epoch 1.9113073348999023
Training time without block to device /epoch 1.8921260833740234
Training time without total dataloading part /epoch 0.01790332794189453
load block tensor time/epoch 0.022920846939086914
block to device time/epoch 0.019181251525878906
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00021 | Loss 2.2350 | Train 0.3340 | Val 0.3867 | Test 0.4263
Number of nodes for computation during this epoch:  491806
Number of first layer input nodes during this epoch:  167734
 full batch blocks save
Number of first layer input nodes during this epoch:  167746
torch.Size([167746, 128])
torch.Size([166694, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.0317535400390625 |0.03698253631591797 |0.00912618637084961 |0.00025773048400878906 |0.004353761672973633 |0.0049397945404052734 |
----------------------------------------------------------pseudo_mini_loss sum 2.200415849685669
Total dataloading + training time/epoch 1.9123877937143499
Training time/epoch 1.8618323802947998
Training time without block to device /epoch 1.8248498439788818
Training time without total dataloading part /epoch 0.018677473068237305
load block tensor time/epoch 0.0317535400390625
block to device time/epoch 0.03698253631591797
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00022 | Loss 2.2004 | Train 0.3304 | Val 0.3789 | Test 0.4203
Number of nodes for computation during this epoch:  491787
Number of first layer input nodes during this epoch:  167746
 full batch blocks save
Number of first layer input nodes during this epoch:  167737
torch.Size([167737, 128])
torch.Size([166656, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.03713822364807129 |0.01830887794494629 |0.007765054702758789 |0.0002167224884033203 |0.004483222961425781 |0.003579378128051758 |
----------------------------------------------------------pseudo_mini_loss sum 2.1555685997009277
Total dataloading + training time/epoch 1.914588098940642
Training time/epoch 1.9628443717956543
Training time without block to device /epoch 1.944535493850708
Training time without total dataloading part /epoch 0.01604437828063965
load block tensor time/epoch 0.03713822364807129
block to device time/epoch 0.01830887794494629
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00023 | Loss 2.1556 | Train 0.3278 | Val 0.3715 | Test 0.4144
Number of nodes for computation during this epoch:  491700
Number of first layer input nodes during this epoch:  167737
 full batch blocks save
Number of first layer input nodes during this epoch:  167741
torch.Size([167741, 128])
torch.Size([166699, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.05220317840576172 |0.02071523666381836 |0.008895158767700195 |0.0002484321594238281 |0.004448890686035156 |0.003585338592529297 |
----------------------------------------------------------pseudo_mini_loss sum 2.1249635219573975
Total dataloading + training time/epoch 1.9153362413247426
Training time/epoch 1.9323463439941406
Training time without block to device /epoch 1.9116311073303223
Training time without total dataloading part /epoch 0.017177820205688477
load block tensor time/epoch 0.05220317840576172
block to device time/epoch 0.02071523666381836
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00024 | Loss 2.1250 | Train 0.3260 | Val 0.3651 | Test 0.4107
Number of nodes for computation during this epoch:  491802
Number of first layer input nodes during this epoch:  167741
 full batch blocks save
Number of first layer input nodes during this epoch:  167748
torch.Size([167748, 128])
torch.Size([166657, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.0359044075012207 |0.01719379425048828 |0.007584571838378906 |0.0002410411834716797 |0.003968238830566406 |0.0036177635192871094 |
----------------------------------------------------------pseudo_mini_loss sum 2.0971803665161133
Total dataloading + training time/epoch 1.911449851989746
Training time/epoch 1.8180279731750488
Training time without block to device /epoch 1.8008341789245605
Training time without total dataloading part /epoch 0.015411615371704102
load block tensor time/epoch 0.0359044075012207
block to device time/epoch 0.01719379425048828
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00025 | Loss 2.0972 | Train 0.3255 | Val 0.3632 | Test 0.4090
Number of nodes for computation during this epoch:  491754
Number of first layer input nodes during this epoch:  167748
 full batch blocks save
Number of first layer input nodes during this epoch:  167732
torch.Size([167732, 128])
torch.Size([166660, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.03743171691894531 |0.01767134666442871 |0.007534503936767578 |0.00020623207092285156 |0.004235744476318359 |0.0035660266876220703 |
----------------------------------------------------------pseudo_mini_loss sum 2.0647318363189697
Total dataloading + training time/epoch 1.9051310924383311
Training time/epoch 1.7470128536224365
Training time without block to device /epoch 1.7293415069580078
Training time without total dataloading part /epoch 0.01554250717163086
load block tensor time/epoch 0.03743171691894531
block to device time/epoch 0.01767134666442871
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00026 | Loss 2.0647 | Train 0.3264 | Val 0.3636 | Test 0.4095
Number of nodes for computation during this epoch:  491771
Number of first layer input nodes during this epoch:  167732
 full batch blocks save
Number of first layer input nodes during this epoch:  167754
torch.Size([167754, 128])
torch.Size([166679, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.06338691711425781 |0.03670239448547363 |0.006571054458618164 |0.0001850128173828125 |0.004342317581176758 |0.0031003952026367188 |
----------------------------------------------------------pseudo_mini_loss sum 2.0397286415100098
Total dataloading + training time/epoch 1.9027166013364438
Training time/epoch 1.8397893905639648
Training time without block to device /epoch 1.8030869960784912
Training time without total dataloading part /epoch 0.014198780059814453
load block tensor time/epoch 0.06338691711425781
block to device time/epoch 0.03670239448547363
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00027 | Loss 2.0397 | Train 0.3296 | Val 0.3676 | Test 0.4128
Number of nodes for computation during this epoch:  491724
Number of first layer input nodes during this epoch:  167754
 full batch blocks save
Number of first layer input nodes during this epoch:  167782
torch.Size([167782, 128])
torch.Size([166670, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.03932499885559082 |0.01757216453552246 |0.0075380802154541016 |0.00019550323486328125 |0.004292488098144531 |0.0034940242767333984 |
----------------------------------------------------------pseudo_mini_loss sum 2.012775421142578
Total dataloading + training time/epoch 1.898709305695125
Training time/epoch 1.7903623580932617
Training time without block to device /epoch 1.7727901935577393
Training time without total dataloading part /epoch 0.015520095825195312
load block tensor time/epoch 0.03932499885559082
block to device time/epoch 0.01757216453552246
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00028 | Loss 2.0128 | Train 0.3337 | Val 0.3736 | Test 0.4181
Number of nodes for computation during this epoch:  491781
Number of first layer input nodes during this epoch:  167782
 full batch blocks save
Number of first layer input nodes during this epoch:  167713
torch.Size([167713, 128])
torch.Size([166666, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.037674903869628906 |0.017578125 |0.0075533390045166016 |0.00022864341735839844 |0.004216432571411133 |0.003454446792602539 |
----------------------------------------------------------pseudo_mini_loss sum 1.988341212272644
Total dataloading + training time/epoch 1.8957853481687348
Training time/epoch 1.813826560974121
Training time without block to device /epoch 1.796248435974121
Training time without total dataloading part /epoch 0.015452861785888672
load block tensor time/epoch 0.037674903869628906
block to device time/epoch 0.017578125
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00029 | Loss 1.9883 | Train 0.3393 | Val 0.3818 | Test 0.4255
Number of nodes for computation during this epoch:  491698
Number of first layer input nodes during this epoch:  167713
 full batch blocks save
Number of first layer input nodes during this epoch:  167715
torch.Size([167715, 128])
torch.Size([166657, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.03787684440612793 |0.01761627197265625 |0.007738351821899414 |0.00025391578674316406 |0.004100799560546875 |0.003447294235229492 |
----------------------------------------------------------pseudo_mini_loss sum 1.9625111818313599
Total dataloading + training time/epoch 1.893419575691223
Training time/epoch 1.8246610164642334
Training time without block to device /epoch 1.8070447444915771
Training time without total dataloading part /epoch 0.015540361404418945
load block tensor time/epoch 0.03787684440612793
block to device time/epoch 0.01761627197265625
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00030 | Loss 1.9625 | Train 0.3462 | Val 0.3923 | Test 0.4337
Number of nodes for computation during this epoch:  491691
Number of first layer input nodes during this epoch:  167715
 full batch blocks save
Number of first layer input nodes during this epoch:  167728
torch.Size([167728, 128])
torch.Size([166685, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.03680133819580078 |0.01750969886779785 |0.008623361587524414 |0.0002758502960205078 |0.004014730453491211 |0.004506111145019531 |
----------------------------------------------------------pseudo_mini_loss sum 1.9469363689422607
Total dataloading + training time/epoch 1.8925244577469365
Training time/epoch 1.8655235767364502
Training time without block to device /epoch 1.8480138778686523
Training time without total dataloading part /epoch 0.017420053482055664
load block tensor time/epoch 0.03680133819580078
block to device time/epoch 0.01750969886779785
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00031 | Loss 1.9469 | Train 0.3536 | Val 0.4034 | Test 0.4426
Number of nodes for computation during this epoch:  491795
Number of first layer input nodes during this epoch:  167728
 full batch blocks save
Number of first layer input nodes during this epoch:  167737
torch.Size([167737, 128])
torch.Size([166662, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.046387434005737305 |0.017980098724365234 |0.009611845016479492 |0.00030541419982910156 |0.004454374313354492 |0.004678964614868164 |
----------------------------------------------------------pseudo_mini_loss sum 1.9243338108062744
Total dataloading + training time/epoch 1.8937303721904755
Training time/epoch 1.9309382438659668
Training time without block to device /epoch 1.9129581451416016
Training time without total dataloading part /epoch 0.01905059814453125
load block tensor time/epoch 0.046387434005737305
block to device time/epoch 0.017980098724365234
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00032 | Loss 1.9243 | Train 0.3614 | Val 0.4139 | Test 0.4516
Number of nodes for computation during this epoch:  491734
Number of first layer input nodes during this epoch:  167737
 full batch blocks save
Number of first layer input nodes during this epoch:  167695
torch.Size([167695, 128])
torch.Size([166665, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.07622075080871582 |0.0264132022857666 |0.006822824478149414 |0.00019240379333496094 |0.004218578338623047 |0.0032188892364501953 |
----------------------------------------------------------pseudo_mini_loss sum 1.9039210081100464
Total dataloading + training time/epoch 1.895474368875677
Training time/epoch 1.9511327743530273
Training time without block to device /epoch 1.9247195720672607
Training time without total dataloading part /epoch 0.014452695846557617
load block tensor time/epoch 0.07622075080871582
block to device time/epoch 0.0264132022857666
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00033 | Loss 1.9039 | Train 0.3688 | Val 0.4235 | Test 0.4595
Number of nodes for computation during this epoch:  491655
Number of first layer input nodes during this epoch:  167695
 full batch blocks save
Number of first layer input nodes during this epoch:  167731
torch.Size([167731, 128])
torch.Size([166676, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.03801584243774414 |0.01754474639892578 |0.007668018341064453 |0.0002028942108154297 |0.004079341888427734 |0.003481626510620117 |
----------------------------------------------------------pseudo_mini_loss sum 1.886892318725586
Total dataloading + training time/epoch 1.8937893474803251
Training time/epoch 1.8380317687988281
Training time without block to device /epoch 1.8204870223999023
Training time without total dataloading part /epoch 0.015431880950927734
load block tensor time/epoch 0.03801584243774414
block to device time/epoch 0.01754474639892578
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00034 | Loss 1.8869 | Train 0.3762 | Val 0.4316 | Test 0.4681
Number of nodes for computation during this epoch:  491701
Number of first layer input nodes during this epoch:  167731
 full batch blocks save
Number of first layer input nodes during this epoch:  167750
torch.Size([167750, 128])
torch.Size([166666, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.03650331497192383 |0.016736745834350586 |0.007769584655761719 |0.00022554397583007812 |0.004346132278442383 |0.0034918785095214844 |
----------------------------------------------------------pseudo_mini_loss sum 1.8546350002288818
Total dataloading + training time/epoch 1.8922559533800398
Training time/epoch 1.8399710655212402
Training time without block to device /epoch 1.8232343196868896
Training time without total dataloading part /epoch 0.015833139419555664
load block tensor time/epoch 0.03650331497192383
block to device time/epoch 0.016736745834350586
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00035 | Loss 1.8546 | Train 0.3824 | Val 0.4393 | Test 0.4736
Number of nodes for computation during this epoch:  491748
Number of first layer input nodes during this epoch:  167750
 full batch blocks save
Number of first layer input nodes during this epoch:  167747
torch.Size([167747, 128])
torch.Size([166690, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.03687715530395508 |0.01923537254333496 |0.007617473602294922 |0.00020813941955566406 |0.004285335540771484 |0.0034093856811523438 |
----------------------------------------------------------pseudo_mini_loss sum 1.8468440771102905
Total dataloading + training time/epoch 1.8908981415960524
Training time/epoch 1.843200445175171
Training time without block to device /epoch 1.823965072631836
Training time without total dataloading part /epoch 0.015520334243774414
load block tensor time/epoch 0.03687715530395508
block to device time/epoch 0.01923537254333496
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00036 | Loss 1.8468 | Train 0.3875 | Val 0.4442 | Test 0.4769
Number of nodes for computation during this epoch:  491705
Number of first layer input nodes during this epoch:  167747
 full batch blocks save
Number of first layer input nodes during this epoch:  167743
torch.Size([167743, 128])
torch.Size([166655, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.046462059020996094 |0.015906572341918945 |0.0073947906494140625 |0.00019884109497070312 |0.004137277603149414 |0.003374814987182617 |
----------------------------------------------------------pseudo_mini_loss sum 1.8297392129898071
Total dataloading + training time/epoch 1.8893082850688212
Training time/epoch 1.8319239616394043
Training time without block to device /epoch 1.8160173892974854
Training time without total dataloading part /epoch 0.015105724334716797
load block tensor time/epoch 0.046462059020996094
block to device time/epoch 0.015906572341918945
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00037 | Loss 1.8297 | Train 0.3920 | Val 0.4489 | Test 0.4781
Number of nodes for computation during this epoch:  491645
Number of first layer input nodes during this epoch:  167743
 full batch blocks save
Number of first layer input nodes during this epoch:  167728
torch.Size([167728, 128])
torch.Size([166677, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.03788924217224121 |0.017704010009765625 |0.00848531723022461 |0.00035643577575683594 |0.004279375076293945 |0.003604412078857422 |
----------------------------------------------------------pseudo_mini_loss sum 1.8092539310455322
Total dataloading + training time/epoch 1.886365388569079
Training time/epoch 1.777327537536621
Training time without block to device /epoch 1.7596235275268555
Training time without total dataloading part /epoch 0.016725540161132812
load block tensor time/epoch 0.03788924217224121
block to device time/epoch 0.017704010009765625
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00038 | Loss 1.8093 | Train 0.3955 | Val 0.4524 | Test 0.4783
Number of nodes for computation during this epoch:  491741
Number of first layer input nodes during this epoch:  167728
 full batch blocks save
Number of first layer input nodes during this epoch:  167730
torch.Size([167730, 128])
torch.Size([166659, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.03585052490234375 |0.01754307746887207 |0.007727384567260742 |0.0002110004425048828 |0.00434565544128418 |0.0035359859466552734 |
----------------------------------------------------------pseudo_mini_loss sum 1.7992030382156372
Total dataloading + training time/epoch 1.8834190429785314
Training time/epoch 1.7713067531585693
Training time without block to device /epoch 1.7537636756896973
Training time without total dataloading part /epoch 0.015820026397705078
load block tensor time/epoch 0.03585052490234375
block to device time/epoch 0.01754307746887207
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00039 | Loss 1.7992 | Train 0.3990 | Val 0.4535 | Test 0.4780
Number of nodes for computation during this epoch:  491766
Number of first layer input nodes during this epoch:  167730
 full batch blocks save
Number of first layer input nodes during this epoch:  167742
torch.Size([167742, 128])
torch.Size([166703, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.04943966865539551 |0.017325639724731445 |0.008026361465454102 |0.0002422332763671875 |0.004505634307861328 |0.003605365753173828 |
----------------------------------------------------------pseudo_mini_loss sum 1.7855496406555176
Total dataloading + training time/epoch 1.8840521991252899
Training time/epoch 1.9085803031921387
Training time without block to device /epoch 1.8912546634674072
Training time without total dataloading part /epoch 0.016379594802856445
load block tensor time/epoch 0.04943966865539551
block to device time/epoch 0.017325639724731445
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00040 | Loss 1.7855 | Train 0.4020 | Val 0.4535 | Test 0.4764
Number of nodes for computation during this epoch:  491770
Number of first layer input nodes during this epoch:  167742
 full batch blocks save
Number of first layer input nodes during this epoch:  167775
torch.Size([167775, 128])
torch.Size([166718, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.03681206703186035 |0.023204326629638672 |0.007665395736694336 |0.0002117156982421875 |0.00431060791015625 |0.003643512725830078 |
----------------------------------------------------------pseudo_mini_loss sum 1.7667572498321533
Total dataloading + training time/epoch 1.88255821204767
Training time/epoch 1.8227119445800781
Training time without block to device /epoch 1.7995076179504395
Training time without total dataloading part /epoch 0.01583123207092285
load block tensor time/epoch 0.03681206703186035
block to device time/epoch 0.023204326629638672
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00041 | Loss 1.7668 | Train 0.4043 | Val 0.4530 | Test 0.4736
Number of nodes for computation during this epoch:  491825
Number of first layer input nodes during this epoch:  167775
 full batch blocks save
Number of first layer input nodes during this epoch:  167753
torch.Size([167753, 128])
torch.Size([166651, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.037261247634887695 |0.02180933952331543 |0.009013652801513672 |0.00025773048400878906 |0.004146099090576172 |0.003862619400024414 |
----------------------------------------------------------pseudo_mini_loss sum 1.748020887374878
Total dataloading + training time/epoch 1.8806024335679554
Training time/epoch 1.8002543449401855
Training time without block to device /epoch 1.7784450054168701
Training time without total dataloading part /epoch 0.017280101776123047
load block tensor time/epoch 0.037261247634887695
block to device time/epoch 0.02180933952331543
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00042 | Loss 1.7480 | Train 0.4062 | Val 0.4535 | Test 0.4710
Number of nodes for computation during this epoch:  491707
Number of first layer input nodes during this epoch:  167753
 full batch blocks save
Number of first layer input nodes during this epoch:  167760
torch.Size([167760, 128])
torch.Size([166683, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.03975963592529297 |0.031012296676635742 |0.007372140884399414 |0.00021982192993164062 |0.0043599605560302734 |0.0036253929138183594 |
----------------------------------------------------------pseudo_mini_loss sum 1.7394132614135742
Total dataloading + training time/epoch 1.884215798488883
Training time/epoch 2.0358259677886963
Training time without block to device /epoch 2.0048136711120605
Training time without total dataloading part /epoch 0.015577316284179688
load block tensor time/epoch 0.03975963592529297
block to device time/epoch 0.031012296676635742
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00043 | Loss 1.7394 | Train 0.4077 | Val 0.4524 | Test 0.4690
Number of nodes for computation during this epoch:  491798
Number of first layer input nodes during this epoch:  167760
 full batch blocks save
Number of first layer input nodes during this epoch:  167706
torch.Size([167706, 128])
torch.Size([166665, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.03291654586791992 |0.018536090850830078 |0.00924062728881836 |0.0002803802490234375 |0.004453182220458984 |0.004862308502197266 |
----------------------------------------------------------pseudo_mini_loss sum 1.7376377582550049
Total dataloading + training time/epoch 1.8861222592267124
Training time/epoch 1.9679265022277832
Training time without block to device /epoch 1.9493904113769531
Training time without total dataloading part /epoch 0.018836498260498047
load block tensor time/epoch 0.03291654586791992
block to device time/epoch 0.018536090850830078
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00044 | Loss 1.7376 | Train 0.4094 | Val 0.4534 | Test 0.4679
Number of nodes for computation during this epoch:  491709
Number of first layer input nodes during this epoch:  167706
 full batch blocks save
Number of first layer input nodes during this epoch:  167699
torch.Size([167699, 128])
torch.Size([166643, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.03248882293701172 |0.02024388313293457 |0.007642984390258789 |0.00023794174194335938 |0.0044231414794921875 |0.0034635066986083984 |
----------------------------------------------------------pseudo_mini_loss sum 1.7162456512451172
Total dataloading + training time/epoch 1.8889785554673937
Training time/epoch 2.0145668983459473
Training time without block to device /epoch 1.9943230152130127
Training time without total dataloading part /epoch 0.015767574310302734
load block tensor time/epoch 0.03248882293701172
block to device time/epoch 0.02024388313293457
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00045 | Loss 1.7162 | Train 0.4105 | Val 0.4533 | Test 0.4669
Number of nodes for computation during this epoch:  491683
Number of first layer input nodes during this epoch:  167699
 full batch blocks save
Number of first layer input nodes during this epoch:  167774
torch.Size([167774, 128])
torch.Size([166720, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.03215360641479492 |0.020820140838623047 |0.008964776992797852 |0.0002486705780029297 |0.004304170608520508 |0.00484919548034668 |
----------------------------------------------------------pseudo_mini_loss sum 1.7095165252685547
Total dataloading + training time/epoch 1.8884987727455471
Training time/epoch 1.8667516708374023
Training time without block to device /epoch 1.8459315299987793
Training time without total dataloading part /epoch 0.01836681365966797
load block tensor time/epoch 0.03215360641479492
block to device time/epoch 0.020820140838623047
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00046 | Loss 1.7095 | Train 0.4115 | Val 0.4536 | Test 0.4672
Number of nodes for computation during this epoch:  491830
Number of first layer input nodes during this epoch:  167774
 full batch blocks save
Number of first layer input nodes during this epoch:  167715
torch.Size([167715, 128])
torch.Size([166630, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.060097455978393555 |0.027838945388793945 |0.006794929504394531 |0.00019598007202148438 |0.004233837127685547 |0.0031883716583251953 |
----------------------------------------------------------pseudo_mini_loss sum 1.6976889371871948
Total dataloading + training time/epoch 1.891458384534146
Training time/epoch 2.0274453163146973
Training time without block to device /epoch 1.9996063709259033
Training time without total dataloading part /epoch 0.014413118362426758
load block tensor time/epoch 0.060097455978393555
block to device time/epoch 0.027838945388793945
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00047 | Loss 1.6977 | Train 0.4120 | Val 0.4545 | Test 0.4675
Number of nodes for computation during this epoch:  491676
Number of first layer input nodes during this epoch:  167715
 full batch blocks save
Number of first layer input nodes during this epoch:  167733
torch.Size([167733, 128])
torch.Size([166679, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.03599286079406738 |0.03421211242675781 |0.007784605026245117 |0.00022745132446289062 |0.004370450973510742 |0.003554821014404297 |
----------------------------------------------------------pseudo_mini_loss sum 1.683743953704834
Total dataloading + training time/epoch 1.8926904946565628
Training time/epoch 1.9504482746124268
Training time without block to device /epoch 1.916236162185669
Training time without total dataloading part /epoch 0.015937328338623047
load block tensor time/epoch 0.03599286079406738
block to device time/epoch 0.03421211242675781
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00048 | Loss 1.6837 | Train 0.4125 | Val 0.4560 | Test 0.4681
Number of nodes for computation during this epoch:  491782
Number of first layer input nodes during this epoch:  167733
 full batch blocks save
Number of first layer input nodes during this epoch:  167717
torch.Size([167717, 128])
torch.Size([166674, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.03741312026977539 |0.021290302276611328 |0.008684873580932617 |0.00024819374084472656 |0.004370689392089844 |0.004664182662963867 |
----------------------------------------------------------pseudo_mini_loss sum 1.6710611581802368
Total dataloading + training time/epoch 1.8954668920867297
Training time/epoch 2.0285804271698
Training time without block to device /epoch 2.0072901248931885
Training time without total dataloading part /epoch 0.017967939376831055
load block tensor time/epoch 0.03741312026977539
block to device time/epoch 0.021290302276611328
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00049 | Loss 1.6711 | Train 0.4134 | Val 0.4569 | Test 0.4695
Number of nodes for computation during this epoch:  491713
Number of first layer input nodes during this epoch:  167717
 full batch blocks save
Number of first layer input nodes during this epoch:  167765
torch.Size([167765, 128])
torch.Size([166666, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.03794717788696289 |0.017734766006469727 |0.00782918930053711 |0.00023603439331054688 |0.00431513786315918 |0.0034809112548828125 |
----------------------------------------------------------pseudo_mini_loss sum 1.662518858909607
Total dataloading + training time/epoch 1.8938890266418458
Training time/epoch 1.8164222240447998
Training time without block to device /epoch 1.79868745803833
Training time without total dataloading part /epoch 0.01586127281188965
load block tensor time/epoch 0.03794717788696289
block to device time/epoch 0.017734766006469727
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00050 | Loss 1.6625 | Train 0.4146 | Val 0.4580 | Test 0.4712
Number of nodes for computation during this epoch:  491711
Number of first layer input nodes during this epoch:  167765
 full batch blocks save
Number of first layer input nodes during this epoch:  167706
torch.Size([167706, 128])
torch.Size([166659, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.03854799270629883 |0.018585681915283203 |0.00782632827758789 |0.0002269744873046875 |0.0037603378295898438 |0.0036156177520751953 |
----------------------------------------------------------pseudo_mini_loss sum 1.658456563949585
Total dataloading + training time/epoch 1.8926797053393196
Training time/epoch 1.8320643901824951
Training time without block to device /epoch 1.813478708267212
Training time without total dataloading part /epoch 0.015429258346557617
load block tensor time/epoch 0.03854799270629883
block to device time/epoch 0.018585681915283203
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00051 | Loss 1.6585 | Train 0.4156 | Val 0.4593 | Test 0.4733
Number of nodes for computation during this epoch:  491731
Number of first layer input nodes during this epoch:  167706
 full batch blocks save
Number of first layer input nodes during this epoch:  167743
torch.Size([167743, 128])
torch.Size([166643, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.04577374458312988 |0.018657207489013672 |0.00828242301940918 |0.00026345252990722656 |0.004346132278442383 |0.00354766845703125 |
----------------------------------------------------------pseudo_mini_loss sum 1.6482688188552856
Total dataloading + training time/epoch 1.893155969106234
Training time/epoch 1.917273998260498
Training time without block to device /epoch 1.8986167907714844
Training time without total dataloading part /epoch 0.01643967628479004
load block tensor time/epoch 0.04577374458312988
block to device time/epoch 0.018657207489013672
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00052 | Loss 1.6483 | Train 0.4165 | Val 0.4609 | Test 0.4760
Number of nodes for computation during this epoch:  491739
Number of first layer input nodes during this epoch:  167743
 full batch blocks save
Number of first layer input nodes during this epoch:  167724
torch.Size([167724, 128])
torch.Size([166691, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.03645443916320801 |0.01773858070373535 |0.007566928863525391 |0.00021123886108398438 |0.0040035247802734375 |0.003629922866821289 |
----------------------------------------------------------pseudo_mini_loss sum 1.6393147706985474
Total dataloading + training time/epoch 1.8921970106520742
Training time/epoch 1.8421807289123535
Training time without block to device /epoch 1.8244421482086182
Training time without total dataloading part /epoch 0.015411615371704102
load block tensor time/epoch 0.03645443916320801
block to device time/epoch 0.01773858070373535
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00053 | Loss 1.6393 | Train 0.4174 | Val 0.4625 | Test 0.4791
Number of nodes for computation during this epoch:  491768
Number of first layer input nodes during this epoch:  167724
 full batch blocks save
Number of first layer input nodes during this epoch:  167723
torch.Size([167723, 128])
torch.Size([166632, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.03638601303100586 |0.0277864933013916 |0.007524251937866211 |0.0002300739288330078 |0.0043871402740478516 |0.003561735153198242 |
----------------------------------------------------------pseudo_mini_loss sum 1.624521017074585
Total dataloading + training time/epoch 1.8916105959150527
Training time/epoch 1.8603813648223877
Training time without block to device /epoch 1.832594871520996
Training time without total dataloading part /epoch 0.015703201293945312
load block tensor time/epoch 0.03638601303100586
block to device time/epoch 0.0277864933013916
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00054 | Loss 1.6245 | Train 0.4184 | Val 0.4644 | Test 0.4818
Number of nodes for computation during this epoch:  491686
Number of first layer input nodes during this epoch:  167723
 full batch blocks save
Number of first layer input nodes during this epoch:  167703
torch.Size([167703, 128])
torch.Size([166650, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.04683327674865723 |0.016682863235473633 |0.0073451995849609375 |0.0002028942108154297 |0.0038657188415527344 |0.0034949779510498047 |
----------------------------------------------------------pseudo_mini_loss sum 1.6196084022521973
Total dataloading + training time/epoch 1.8909281904047186
Training time/epoch 1.8539001941680908
Training time without block to device /epoch 1.8372173309326172
Training time without total dataloading part /epoch 0.014908790588378906
load block tensor time/epoch 0.04683327674865723
block to device time/epoch 0.016682863235473633
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00055 | Loss 1.6196 | Train 0.4192 | Val 0.4659 | Test 0.4845
Number of nodes for computation during this epoch:  491602
Number of first layer input nodes during this epoch:  167703
 full batch blocks save
Number of first layer input nodes during this epoch:  167734
torch.Size([167734, 128])
torch.Size([166661, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.03720736503601074 |0.018637418746948242 |0.009454011917114258 |0.0002956390380859375 |0.004279375076293945 |0.0047757625579833984 |
----------------------------------------------------------pseudo_mini_loss sum 1.6079881191253662
Total dataloading + training time/epoch 1.8902658862727029
Training time/epoch 1.8536860942840576
Training time without block to device /epoch 1.8350486755371094
Training time without total dataloading part /epoch 0.01880478858947754
load block tensor time/epoch 0.03720736503601074
block to device time/epoch 0.018637418746948242
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00056 | Loss 1.6080 | Train 0.4201 | Val 0.4676 | Test 0.4869
Number of nodes for computation during this epoch:  491756
Number of first layer input nodes during this epoch:  167734
 full batch blocks save
Number of first layer input nodes during this epoch:  167735
torch.Size([167735, 128])
torch.Size([166637, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.037783145904541016 |0.0185854434967041 |0.008829355239868164 |0.00024819374084472656 |0.0040547847747802734 |0.004859209060668945 |
----------------------------------------------------------pseudo_mini_loss sum 1.5995090007781982
Total dataloading + training time/epoch 1.8902889636524938
Training time/epoch 1.891427993774414
Training time without block to device /epoch 1.87284255027771
Training time without total dataloading part /epoch 0.01799154281616211
load block tensor time/epoch 0.037783145904541016
block to device time/epoch 0.0185854434967041
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00057 | Loss 1.5995 | Train 0.4209 | Val 0.4694 | Test 0.4900
Number of nodes for computation during this epoch:  491745
Number of first layer input nodes during this epoch:  167735
 full batch blocks save
Number of first layer input nodes during this epoch:  167723
torch.Size([167723, 128])
torch.Size([166636, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.047919273376464844 |0.03966665267944336 |0.007825374603271484 |0.00023221969604492188 |0.004080295562744141 |0.004084587097167969 |
----------------------------------------------------------pseudo_mini_loss sum 1.596937894821167
Total dataloading + training time/epoch 1.8917905667732502
Training time/epoch 1.9772207736968994
Training time without block to device /epoch 1.937554121017456
Training time without total dataloading part /epoch 0.016222476959228516
load block tensor time/epoch 0.047919273376464844
block to device time/epoch 0.03966665267944336
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00058 | Loss 1.5969 | Train 0.4221 | Val 0.4714 | Test 0.4921
Number of nodes for computation during this epoch:  491657
Number of first layer input nodes during this epoch:  167723
 full batch blocks save
Number of first layer input nodes during this epoch:  167753
torch.Size([167753, 128])
torch.Size([166712, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.039109230041503906 |0.018267393112182617 |0.008185863494873047 |0.00024199485778808594 |0.004095792770385742 |0.003779888153076172 |
----------------------------------------------------------pseudo_mini_loss sum 1.5870344638824463
Total dataloading + training time/epoch 1.8917565547813804
Training time/epoch 1.889634370803833
Training time without block to device /epoch 1.8713669776916504
Training time without total dataloading part /epoch 0.016303539276123047
load block tensor time/epoch 0.039109230041503906
block to device time/epoch 0.018267393112182617
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00059 | Loss 1.5870 | Train 0.4229 | Val 0.4724 | Test 0.4942
Number of nodes for computation during this epoch:  491804
Number of first layer input nodes during this epoch:  167753
 full batch blocks save
Number of first layer input nodes during this epoch:  167685
torch.Size([167685, 128])
torch.Size([166620, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.04981374740600586 |0.01685309410095215 |0.007331132888793945 |0.00019812583923339844 |0.0037424564361572266 |0.003531217575073242 |
----------------------------------------------------------pseudo_mini_loss sum 1.5764061212539673
Total dataloading + training time/epoch 1.8931815385818482
Training time/epoch 1.9771039485931396
Training time without block to device /epoch 1.9602508544921875
Training time without total dataloading part /epoch 0.014802932739257812
load block tensor time/epoch 0.04981374740600586
block to device time/epoch 0.01685309410095215
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00060 | Loss 1.5764 | Train 0.4240 | Val 0.4732 | Test 0.4960
Number of nodes for computation during this epoch:  491596
Number of first layer input nodes during this epoch:  167685
 full batch blocks save
Number of first layer input nodes during this epoch:  167756
torch.Size([167756, 128])
torch.Size([166685, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.03801155090332031 |0.01738429069519043 |0.0075871944427490234 |0.0002129077911376953 |0.0031442642211914062 |0.0034728050231933594 |
----------------------------------------------------------pseudo_mini_loss sum 1.5673930644989014
Total dataloading + training time/epoch 1.8924182712054642
Training time/epoch 1.8464691638946533
Training time without block to device /epoch 1.829084873199463
Training time without total dataloading part /epoch 0.014417171478271484
load block tensor time/epoch 0.03801155090332031
block to device time/epoch 0.01738429069519043
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00061 | Loss 1.5674 | Train 0.4250 | Val 0.4748 | Test 0.4980
Number of nodes for computation during this epoch:  491780
Number of first layer input nodes during this epoch:  167756
 full batch blocks save
Number of first layer input nodes during this epoch:  167766
torch.Size([167766, 128])
torch.Size([166700, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.03666353225708008 |0.017904996871948242 |0.008107185363769531 |0.00024437904357910156 |0.004181861877441406 |0.0037505626678466797 |
----------------------------------------------------------pseudo_mini_loss sum 1.5630862712860107
Total dataloading + training time/epoch 1.891560019985322
Training time/epoch 1.8390650749206543
Training time without block to device /epoch 1.821160078048706
Training time without total dataloading part /epoch 0.01628398895263672
load block tensor time/epoch 0.03666353225708008
block to device time/epoch 0.017904996871948242
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00062 | Loss 1.5631 | Train 0.4259 | Val 0.4758 | Test 0.4998
Number of nodes for computation during this epoch:  491810
Number of first layer input nodes during this epoch:  167766
 full batch blocks save
Number of first layer input nodes during this epoch:  167717
torch.Size([167717, 128])
torch.Size([166631, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.03744387626647949 |0.018915653228759766 |0.008262395858764648 |0.00023603439331054688 |0.004018306732177734 |0.003690481185913086 |
----------------------------------------------------------pseudo_mini_loss sum 1.5573359727859497
Total dataloading + training time/epoch 1.8923285310230558
Training time/epoch 1.9398255348205566
Training time without block to device /epoch 1.9209098815917969
Training time without total dataloading part /epoch 0.016207218170166016
load block tensor time/epoch 0.03744387626647949
block to device time/epoch 0.018915653228759766
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00063 | Loss 1.5573 | Train 0.4269 | Val 0.4770 | Test 0.5011
Number of nodes for computation during this epoch:  491713
Number of first layer input nodes during this epoch:  167717
 full batch blocks save
Number of first layer input nodes during this epoch:  167711
torch.Size([167711, 128])
torch.Size([166654, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.036585092544555664 |0.020501136779785156 |0.00766444206237793 |0.00021195411682128906 |0.0040283203125 |0.0034356117248535156 |
----------------------------------------------------------pseudo_mini_loss sum 1.5548211336135864
Total dataloading + training time/epoch 1.8917369320988655
Training time/epoch 1.854318380355835
Training time without block to device /epoch 1.8338172435760498
Training time without total dataloading part /epoch 0.015340328216552734
load block tensor time/epoch 0.036585092544555664
block to device time/epoch 0.020501136779785156
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00064 | Loss 1.5548 | Train 0.4280 | Val 0.4779 | Test 0.5025
Number of nodes for computation during this epoch:  491771
Number of first layer input nodes during this epoch:  167711
 full batch blocks save
Number of first layer input nodes during this epoch:  167765
torch.Size([167765, 128])
torch.Size([166728, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.0485689640045166 |0.01922774314880371 |0.01003408432006836 |0.0003063678741455078 |0.00429224967956543 |0.004857063293457031 |
----------------------------------------------------------pseudo_mini_loss sum 1.544990062713623
Total dataloading + training time/epoch 1.89329546048091
Training time/epoch 1.992764949798584
Training time without block to device /epoch 1.9735372066497803
Training time without total dataloading part /epoch 0.019489765167236328
load block tensor time/epoch 0.0485689640045166
block to device time/epoch 0.01922774314880371
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00065 | Loss 1.5450 | Train 0.4291 | Val 0.4790 | Test 0.5037
Number of nodes for computation during this epoch:  491849
Number of first layer input nodes during this epoch:  167765
 full batch blocks save
Number of first layer input nodes during this epoch:  167765
torch.Size([167765, 128])
torch.Size([166730, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.04791665077209473 |0.03315567970275879 |0.0917212963104248 |0.00019431114196777344 |0.22188639640808105 |0.0044138431549072266 |
----------------------------------------------------------pseudo_mini_loss sum 1.5378307104110718
Total dataloading + training time/epoch 1.8952067331834273
Training time/epoch 2.0192811489105225
Training time without block to device /epoch 1.9861254692077637
Training time without total dataloading part /epoch 0.31821584701538086
load block tensor time/epoch 0.04791665077209473
block to device time/epoch 0.03315567970275879
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00066 | Loss 1.5378 | Train 0.4301 | Val 0.4801 | Test 0.5050
Number of nodes for computation during this epoch:  491924
Number of first layer input nodes during this epoch:  167765
 full batch blocks save
Number of first layer input nodes during this epoch:  167759
torch.Size([167759, 128])
torch.Size([166712, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.037065982818603516 |0.017848730087280273 |0.009067296981811523 |0.0002770423889160156 |0.003962993621826172 |0.0045888423919677734 |
----------------------------------------------------------pseudo_mini_loss sum 1.5342004299163818
Total dataloading + training time/epoch 1.8963779869364268
Training time/epoch 1.9735243320465088
Training time without block to device /epoch 1.9556756019592285
Training time without total dataloading part /epoch 0.017896175384521484
load block tensor time/epoch 0.037065982818603516
block to device time/epoch 0.017848730087280273
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00067 | Loss 1.5342 | Train 0.4310 | Val 0.4812 | Test 0.5066
Number of nodes for computation during this epoch:  491813
Number of first layer input nodes during this epoch:  167759
 full batch blocks save
Number of first layer input nodes during this epoch:  167719
torch.Size([167719, 128])
torch.Size([166668, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.04700064659118652 |0.017229795455932617 |0.008293390274047852 |0.0002543926239013672 |0.003982067108154297 |0.004418849945068359 |
----------------------------------------------------------pseudo_mini_loss sum 1.5296916961669922
Total dataloading + training time/epoch 1.8977171077447779
Training time/epoch 1.9873523712158203
Training time without block to device /epoch 1.9701225757598877
Training time without total dataloading part /epoch 0.016948699951171875
load block tensor time/epoch 0.04700064659118652
block to device time/epoch 0.017229795455932617
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00068 | Loss 1.5297 | Train 0.4321 | Val 0.4824 | Test 0.5077
Number of nodes for computation during this epoch:  491725
Number of first layer input nodes during this epoch:  167719
 full batch blocks save
Number of first layer input nodes during this epoch:  167764
torch.Size([167764, 128])
torch.Size([166691, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.037064552307128906 |0.021431684494018555 |0.008482694625854492 |0.0002529621124267578 |0.0044384002685546875 |0.003665447235107422 |
----------------------------------------------------------pseudo_mini_loss sum 1.5191622972488403
Total dataloading + training time/epoch 1.8965741655100947
Training time/epoch 1.8187034130096436
Training time without block to device /epoch 1.797271728515625
Training time without total dataloading part /epoch 0.01683950424194336
load block tensor time/epoch 0.037064552307128906
block to device time/epoch 0.021431684494018555
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00069 | Loss 1.5192 | Train 0.4329 | Val 0.4832 | Test 0.5092
Number of nodes for computation during this epoch:  491776
Number of first layer input nodes during this epoch:  167764
 full batch blocks save
Number of first layer input nodes during this epoch:  167746
torch.Size([167746, 128])
torch.Size([166684, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.03667140007019043 |0.01875162124633789 |0.008923053741455078 |0.0002410411834716797 |0.0038068294525146484 |0.004658937454223633 |
----------------------------------------------------------pseudo_mini_loss sum 1.5127356052398682
Total dataloading + training time/epoch 1.8971967356545585
Training time/epoch 1.939997673034668
Training time without block to device /epoch 1.92124605178833
Training time without total dataloading part /epoch 0.01762986183166504
load block tensor time/epoch 0.03667140007019043
block to device time/epoch 0.01875162124633789
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00070 | Loss 1.5127 | Train 0.4340 | Val 0.4841 | Test 0.5103
Number of nodes for computation during this epoch:  491789
Number of first layer input nodes during this epoch:  167746
 full batch blocks save
Number of first layer input nodes during this epoch:  167724
torch.Size([167724, 128])
torch.Size([166684, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.08473896980285645 |0.029638290405273438 |0.0074617862701416016 |0.0002155303955078125 |0.004374265670776367 |0.003998994827270508 |
----------------------------------------------------------pseudo_mini_loss sum 1.505068302154541
Total dataloading + training time/epoch 1.8984793844357344
Training time/epoch 1.9881701469421387
Training time without block to device /epoch 1.9585318565368652
Training time without total dataloading part /epoch 0.01605057716369629
load block tensor time/epoch 0.08473896980285645
block to device time/epoch 0.029638290405273438
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00071 | Loss 1.5051 | Train 0.4349 | Val 0.4856 | Test 0.5114
Number of nodes for computation during this epoch:  491714
Number of first layer input nodes during this epoch:  167724
 full batch blocks save
Number of first layer input nodes during this epoch:  167792
torch.Size([167792, 128])
torch.Size([166731, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.032706260681152344 |0.017032623291015625 |0.008453130722045898 |0.0003628730773925781 |0.004048585891723633 |0.0047338008880615234 |
----------------------------------------------------------pseudo_mini_loss sum 1.5061968564987183
Total dataloading + training time/epoch 1.900355726480484
Training time/epoch 2.0334205627441406
Training time without block to device /epoch 2.016387939453125
Training time without total dataloading part /epoch 0.017598390579223633
load block tensor time/epoch 0.032706260681152344
block to device time/epoch 0.017032623291015625
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00072 | Loss 1.5062 | Train 0.4357 | Val 0.4867 | Test 0.5126
Number of nodes for computation during this epoch:  491888
Number of first layer input nodes during this epoch:  167792
 full batch blocks save
Number of first layer input nodes during this epoch:  167793
torch.Size([167793, 128])
torch.Size([166728, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.0374908447265625 |0.032108306884765625 |0.008900165557861328 |0.00026917457580566406 |0.0044443607330322266 |0.004591941833496094 |
----------------------------------------------------------pseudo_mini_loss sum 1.4967924356460571
Total dataloading + training time/epoch 1.9010037298071873
Training time/epoch 1.9474961757659912
Training time without block to device /epoch 1.9153878688812256
Training time without total dataloading part /epoch 0.018205642700195312
load block tensor time/epoch 0.0374908447265625
block to device time/epoch 0.032108306884765625
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00073 | Loss 1.4968 | Train 0.4366 | Val 0.4880 | Test 0.5137
Number of nodes for computation during this epoch:  491878
Number of first layer input nodes during this epoch:  167793
 full batch blocks save
Number of first layer input nodes during this epoch:  167722
torch.Size([167722, 128])
torch.Size([166662, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.03757643699645996 |0.018924951553344727 |0.008955240249633789 |0.00024366378784179688 |0.003981113433837891 |0.00479435920715332 |
----------------------------------------------------------pseudo_mini_loss sum 1.492086410522461
Total dataloading + training time/epoch 1.901729222890493
Training time/epoch 1.954599142074585
Training time without block to device /epoch 1.9356741905212402
Training time without total dataloading part /epoch 0.017974376678466797
load block tensor time/epoch 0.03757643699645996
block to device time/epoch 0.018924951553344727
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00074 | Loss 1.4921 | Train 0.4376 | Val 0.4889 | Test 0.5148
Number of nodes for computation during this epoch:  491741
Number of first layer input nodes during this epoch:  167722
 full batch blocks save
Number of first layer input nodes during this epoch:  167739
torch.Size([167739, 128])
torch.Size([166671, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.038202762603759766 |0.017509937286376953 |0.008070945739746094 |0.00024247169494628906 |0.004241943359375 |0.0036776065826416016 |
----------------------------------------------------------pseudo_mini_loss sum 1.4798442125320435
Total dataloading + training time/epoch 1.9009197107950846
Training time/epoch 1.8409323692321777
Training time without block to device /epoch 1.8234224319458008
Training time without total dataloading part /epoch 0.016232967376708984
load block tensor time/epoch 0.038202762603759766
block to device time/epoch 0.017509937286376953
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00075 | Loss 1.4798 | Train 0.4386 | Val 0.4899 | Test 0.5159
Number of nodes for computation during this epoch:  491749
Number of first layer input nodes during this epoch:  167739
 full batch blocks save
Number of first layer input nodes during this epoch:  167727
torch.Size([167727, 128])
torch.Size([166650, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.04529738426208496 |0.021855592727661133 |0.007408618927001953 |0.00019598007202148438 |0.0043070316314697266 |0.0034041404724121094 |
----------------------------------------------------------pseudo_mini_loss sum 1.4830386638641357
Total dataloading + training time/epoch 1.9010359048843384
Training time/epoch 1.9096617698669434
Training time without block to device /epoch 1.8878061771392822
Training time without total dataloading part /epoch 0.015315771102905273
load block tensor time/epoch 0.04529738426208496
block to device time/epoch 0.021855592727661133
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00076 | Loss 1.4830 | Train 0.4396 | Val 0.4911 | Test 0.5172
Number of nodes for computation during this epoch:  491755
Number of first layer input nodes during this epoch:  167727
 full batch blocks save
Number of first layer input nodes during this epoch:  167744
torch.Size([167744, 128])
torch.Size([166671, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.03753781318664551 |0.017791748046875 |0.0075414180755615234 |0.00020599365234375 |0.004035234451293945 |0.003657102584838867 |
----------------------------------------------------------pseudo_mini_loss sum 1.478957176208496
Total dataloading + training time/epoch 1.8994583959703322
Training time/epoch 1.7794175148010254
Training time without block to device /epoch 1.7616257667541504
Training time without total dataloading part /epoch 0.015439748764038086
load block tensor time/epoch 0.03753781318664551
block to device time/epoch 0.017791748046875
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00077 | Loss 1.4790 | Train 0.4405 | Val 0.4918 | Test 0.5180
Number of nodes for computation during this epoch:  491784
Number of first layer input nodes during this epoch:  167744
 full batch blocks save
Number of first layer input nodes during this epoch:  167753
torch.Size([167753, 128])
torch.Size([166701, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.0375368595123291 |0.01799917221069336 |0.007899999618530273 |0.000232696533203125 |0.004112958908081055 |0.0036356449127197266 |
----------------------------------------------------------pseudo_mini_loss sum 1.463592290878296
Total dataloading + training time/epoch 1.89929644878094
Training time/epoch 1.886673927307129
Training time without block to device /epoch 1.8686747550964355
Training time without total dataloading part /epoch 0.01588129997253418
load block tensor time/epoch 0.0375368595123291
block to device time/epoch 0.01799917221069336
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00078 | Loss 1.4636 | Train 0.4416 | Val 0.4927 | Test 0.5191
Number of nodes for computation during this epoch:  491775
Number of first layer input nodes during this epoch:  167753
 full batch blocks save
Number of first layer input nodes during this epoch:  167714
torch.Size([167714, 128])
torch.Size([166677, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.04926800727844238 |0.0169219970703125 |0.007911920547485352 |0.00024819374084472656 |0.004004716873168945 |0.003573179244995117 |
----------------------------------------------------------pseudo_mini_loss sum 1.4616243839263916
Total dataloading + training time/epoch 1.8986158914203886
Training time/epoch 1.8453612327575684
Training time without block to device /epoch 1.8284392356872559
Training time without total dataloading part /epoch 0.01573801040649414
load block tensor time/epoch 0.04926800727844238
block to device time/epoch 0.0169219970703125
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00079 | Loss 1.4616 | Train 0.4425 | Val 0.4940 | Test 0.5201
Number of nodes for computation during this epoch:  491746
Number of first layer input nodes during this epoch:  167714
 full batch blocks save
Number of first layer input nodes during this epoch:  167754
torch.Size([167754, 128])
torch.Size([166685, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.03649139404296875 |0.017738819122314453 |0.007578372955322266 |0.00019693374633789062 |0.003935337066650391 |0.003532886505126953 |
----------------------------------------------------------pseudo_mini_loss sum 1.4596298933029175
Total dataloading + training time/epoch 1.8973889857530595
Training time/epoch 1.8003125190734863
Training time without block to device /epoch 1.7825736999511719
Training time without total dataloading part /epoch 0.0152435302734375
load block tensor time/epoch 0.03649139404296875
block to device time/epoch 0.017738819122314453
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00080 | Loss 1.4596 | Train 0.4431 | Val 0.4945 | Test 0.5209
Number of nodes for computation during this epoch:  491782
Number of first layer input nodes during this epoch:  167754
 full batch blocks save
Number of first layer input nodes during this epoch:  167753
torch.Size([167753, 128])
torch.Size([166654, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.037328481674194336 |0.018919944763183594 |0.008032083511352539 |0.0002446174621582031 |0.00437164306640625 |0.003584623336791992 |
----------------------------------------------------------pseudo_mini_loss sum 1.4566994905471802
Total dataloading + training time/epoch 1.8960225228910093
Training time/epoch 1.7866177558898926
Training time without block to device /epoch 1.767697811126709
Training time without total dataloading part /epoch 0.016232967376708984
load block tensor time/epoch 0.037328481674194336
block to device time/epoch 0.018919944763183594
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00081 | Loss 1.4567 | Train 0.4438 | Val 0.4954 | Test 0.5217
Number of nodes for computation during this epoch:  491745
Number of first layer input nodes during this epoch:  167753
 full batch blocks save
Number of first layer input nodes during this epoch:  167764
torch.Size([167764, 128])
torch.Size([166693, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.037011146545410156 |0.017955780029296875 |0.007725715637207031 |0.0002219676971435547 |0.0038449764251708984 |0.0035490989685058594 |
----------------------------------------------------------pseudo_mini_loss sum 1.4545220136642456
Total dataloading + training time/epoch 1.8944875467114333
Training time/epoch 1.7700092792510986
Training time without block to device /epoch 1.7520534992218018
Training time without total dataloading part /epoch 0.015341758728027344
load block tensor time/epoch 0.037011146545410156
block to device time/epoch 0.017955780029296875
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00082 | Loss 1.4545 | Train 0.4444 | Val 0.4965 | Test 0.5225
Number of nodes for computation during this epoch:  491849
Number of first layer input nodes during this epoch:  167764
 full batch blocks save
Number of first layer input nodes during this epoch:  167744
torch.Size([167744, 128])
torch.Size([166682, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.048613786697387695 |0.018503189086914062 |0.007860660552978516 |0.0002269744873046875 |0.0038764476776123047 |0.003655672073364258 |
----------------------------------------------------------pseudo_mini_loss sum 1.4440279006958008
Total dataloading + training time/epoch 1.8951046983879734
Training time/epoch 1.9456210136413574
Training time without block to device /epoch 1.9271178245544434
Training time without total dataloading part /epoch 0.015619754791259766
load block tensor time/epoch 0.048613786697387695
block to device time/epoch 0.018503189086914062
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00083 | Loss 1.4440 | Train 0.4451 | Val 0.4968 | Test 0.5231
Number of nodes for computation during this epoch:  491788
Number of first layer input nodes during this epoch:  167744
 full batch blocks save
Number of first layer input nodes during this epoch:  167718
torch.Size([167718, 128])
torch.Size([166643, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.03667330741882324 |0.0200045108795166 |0.007523298263549805 |0.0001995563507080078 |0.0038652420043945312 |0.0034537315368652344 |
----------------------------------------------------------pseudo_mini_loss sum 1.4413678646087646
Total dataloading + training time/epoch 1.8945764303207397
Training time/epoch 1.850579023361206
Training time without block to device /epoch 1.8305745124816895
Training time without total dataloading part /epoch 0.015041828155517578
load block tensor time/epoch 0.03667330741882324
block to device time/epoch 0.0200045108795166
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00084 | Loss 1.4414 | Train 0.4459 | Val 0.4976 | Test 0.5241
Number of nodes for computation during this epoch:  491715
Number of first layer input nodes during this epoch:  167718
 full batch blocks save
Number of first layer input nodes during this epoch:  167788
torch.Size([167788, 128])
torch.Size([166705, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.03815150260925293 |0.025182008743286133 |0.0081024169921875 |0.00026702880859375 |0.004189014434814453 |0.0035033226013183594 |
----------------------------------------------------------pseudo_mini_loss sum 1.431349515914917
Total dataloading + training time/epoch 1.8942299365997315
Training time/epoch 1.864971399307251
Training time without block to device /epoch 1.8397893905639648
Training time without total dataloading part /epoch 0.016061782836914062
load block tensor time/epoch 0.03815150260925293
block to device time/epoch 0.025182008743286133
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00085 | Loss 1.4313 | Train 0.4465 | Val 0.4984 | Test 0.5248
Number of nodes for computation during this epoch:  491832
Number of first layer input nodes during this epoch:  167788
 full batch blocks save
Number of first layer input nodes during this epoch:  167761
torch.Size([167761, 128])
torch.Size([166660, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.036647796630859375 |0.018164396286010742 |0.007666349411010742 |0.0002148151397705078 |0.003982067108154297 |0.0034797191619873047 |
----------------------------------------------------------pseudo_mini_loss sum 1.4313422441482544
Total dataloading + training time/epoch 1.8943577893944674
Training time/epoch 1.9050781726837158
Training time without block to device /epoch 1.886913776397705
Training time without total dataloading part /epoch 0.015342950820922852
load block tensor time/epoch 0.036647796630859375
block to device time/epoch 0.018164396286010742
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00086 | Loss 1.4313 | Train 0.4471 | Val 0.4994 | Test 0.5255
Number of nodes for computation during this epoch:  491795
Number of first layer input nodes during this epoch:  167761
 full batch blocks save
Number of first layer input nodes during this epoch:  167740
torch.Size([167740, 128])
torch.Size([166681, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.03812432289123535 |0.018436193466186523 |0.008261442184448242 |0.0002524852752685547 |0.00404047966003418 |0.0036699771881103516 |
----------------------------------------------------------pseudo_mini_loss sum 1.4278358221054077
Total dataloading + training time/epoch 1.8949518998463948
Training time/epoch 1.9458942413330078
Training time without block to device /epoch 1.9274580478668213
Training time without total dataloading part /epoch 0.016224384307861328
load block tensor time/epoch 0.03812432289123535
block to device time/epoch 0.018436193466186523
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00087 | Loss 1.4278 | Train 0.4479 | Val 0.4995 | Test 0.5257
Number of nodes for computation during this epoch:  491788
Number of first layer input nodes during this epoch:  167740
 full batch blocks save
Number of first layer input nodes during this epoch:  167746
torch.Size([167746, 128])
torch.Size([166687, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.03797483444213867 |0.018610715866088867 |0.008434534072875977 |0.000244140625 |0.004214763641357422 |0.004637956619262695 |
----------------------------------------------------------pseudo_mini_loss sum 1.4235899448394775
Total dataloading + training time/epoch 1.8950918262655085
Training time/epoch 1.9070897102355957
Training time without block to device /epoch 1.8884789943695068
Training time without total dataloading part /epoch 0.017531394958496094
load block tensor time/epoch 0.03797483444213867
block to device time/epoch 0.018610715866088867
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00088 | Loss 1.4236 | Train 0.4485 | Val 0.5000 | Test 0.5264
Number of nodes for computation during this epoch:  491694
Number of first layer input nodes during this epoch:  167746
 full batch blocks save
Number of first layer input nodes during this epoch:  167742
torch.Size([167742, 128])
torch.Size([166688, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.046399831771850586 |0.020865917205810547 |0.008619546890258789 |0.0002453327178955078 |0.0044214725494384766 |0.004837989807128906 |
----------------------------------------------------------pseudo_mini_loss sum 1.4211349487304688
Total dataloading + training time/epoch 1.895964137623819
Training time/epoch 1.9725782871246338
Training time without block to device /epoch 1.9517123699188232
Training time without total dataloading part /epoch 0.01812434196472168
load block tensor time/epoch 0.046399831771850586
block to device time/epoch 0.020865917205810547
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00089 | Loss 1.4211 | Train 0.4491 | Val 0.5004 | Test 0.5267
Number of nodes for computation during this epoch:  491813
Number of first layer input nodes during this epoch:  167742
 full batch blocks save
Number of first layer input nodes during this epoch:  167760
torch.Size([167760, 128])
torch.Size([166661, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.03835153579711914 |0.01762866973876953 |0.009119510650634766 |0.0002760887145996094 |0.004465341567993164 |0.004723310470581055 |
----------------------------------------------------------pseudo_mini_loss sum 1.4202276468276978
Total dataloading + training time/epoch 1.8954805639055041
Training time/epoch 1.8522891998291016
Training time without block to device /epoch 1.834660530090332
Training time without total dataloading part /epoch 0.018584251403808594
load block tensor time/epoch 0.03835153579711914
block to device time/epoch 0.01762866973876953
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00090 | Loss 1.4202 | Train 0.4498 | Val 0.5004 | Test 0.5273
Number of nodes for computation during this epoch:  491732
Number of first layer input nodes during this epoch:  167760
 full batch blocks save
Number of first layer input nodes during this epoch:  167740
torch.Size([167740, 128])
torch.Size([166661, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.0536198616027832 |0.020886659622192383 |0.00715327262878418 |0.00019931793212890625 |0.004441261291503906 |0.003355264663696289 |
----------------------------------------------------------pseudo_mini_loss sum 1.4090380668640137
Total dataloading + training time/epoch 1.8970897381122296
Training time/epoch 2.0418248176574707
Training time without block to device /epoch 2.0209381580352783
Training time without total dataloading part /epoch 0.015149116516113281
load block tensor time/epoch 0.0536198616027832
block to device time/epoch 0.020886659622192383
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00091 | Loss 1.4090 | Train 0.4504 | Val 0.5009 | Test 0.5278
Number of nodes for computation during this epoch:  491758
Number of first layer input nodes during this epoch:  167740
 full batch blocks save
Number of first layer input nodes during this epoch:  167773
torch.Size([167773, 128])
torch.Size([166717, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.03492903709411621 |0.016424179077148438 |0.0072896480560302734 |0.00019860267639160156 |0.003811359405517578 |0.0034575462341308594 |
----------------------------------------------------------pseudo_mini_loss sum 1.4050720930099487
Total dataloading + training time/epoch 1.8962759842043337
Training time/epoch 1.8221335411071777
Training time without block to device /epoch 1.8057093620300293
Training time without total dataloading part /epoch 0.014757156372070312
load block tensor time/epoch 0.03492903709411621
block to device time/epoch 0.016424179077148438
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00092 | Loss 1.4051 | Train 0.4511 | Val 0.5012 | Test 0.5284
Number of nodes for computation during this epoch:  491865
Number of first layer input nodes during this epoch:  167773
 full batch blocks save
Number of first layer input nodes during this epoch:  167750
torch.Size([167750, 128])
torch.Size([166687, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.04085397720336914 |0.02825188636779785 |0.007546901702880859 |0.00023627281188964844 |0.004358768463134766 |0.0034418106079101562 |
----------------------------------------------------------pseudo_mini_loss sum 1.399764060974121
Total dataloading + training time/epoch 1.8959609513641686
Training time/epoch 1.8668241500854492
Training time without block to device /epoch 1.8385722637176514
Training time without total dataloading part /epoch 0.01558375358581543
load block tensor time/epoch 0.04085397720336914
block to device time/epoch 0.02825188636779785
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00093 | Loss 1.3998 | Train 0.4520 | Val 0.5020 | Test 0.5294
Number of nodes for computation during this epoch:  491746
Number of first layer input nodes during this epoch:  167750
 full batch blocks save
Number of first layer input nodes during this epoch:  167733
torch.Size([167733, 128])
torch.Size([166681, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.037850141525268555 |0.018920183181762695 |0.007668018341064453 |0.00022912025451660156 |0.004167795181274414 |0.003569364547729492 |
----------------------------------------------------------pseudo_mini_loss sum 1.3998361825942993
Total dataloading + training time/epoch 1.8958504453618477
Training time/epoch 1.8854219913482666
Training time without block to device /epoch 1.866501808166504
Training time without total dataloading part /epoch 0.01563429832458496
load block tensor time/epoch 0.037850141525268555
block to device time/epoch 0.018920183181762695
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00094 | Loss 1.3998 | Train 0.4529 | Val 0.5029 | Test 0.5305
Number of nodes for computation during this epoch:  491774
Number of first layer input nodes during this epoch:  167733
 full batch blocks save
Number of first layer input nodes during this epoch:  167717
torch.Size([167717, 128])
torch.Size([166691, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.03747868537902832 |0.017722129821777344 |0.007569789886474609 |0.000244140625 |0.004018545150756836 |0.003668069839477539 |
----------------------------------------------------------pseudo_mini_loss sum 1.3920754194259644
Total dataloading + training time/epoch 1.895255906958329
Training time/epoch 1.8391878604888916
Training time without block to device /epoch 1.8214657306671143
Training time without total dataloading part /epoch 0.015500545501708984
load block tensor time/epoch 0.03747868537902832
block to device time/epoch 0.017722129821777344
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00095 | Loss 1.3921 | Train 0.4537 | Val 0.5037 | Test 0.5311
Number of nodes for computation during this epoch:  491808
Number of first layer input nodes during this epoch:  167717
 full batch blocks save
Number of first layer input nodes during this epoch:  167727
torch.Size([167727, 128])
torch.Size([166618, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.03796195983886719 |0.017618417739868164 |0.00782465934753418 |0.00021648406982421875 |0.004101753234863281 |0.0035686492919921875 |
----------------------------------------------------------pseudo_mini_loss sum 1.3870490789413452
Total dataloading + training time/epoch 1.894549364844958
Training time/epoch 1.8273377418518066
Training time without block to device /epoch 1.8097193241119385
Training time without total dataloading part /epoch 0.015711545944213867
load block tensor time/epoch 0.03796195983886719
block to device time/epoch 0.017618417739868164
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00096 | Loss 1.3870 | Train 0.4545 | Val 0.5042 | Test 0.5322
Number of nodes for computation during this epoch:  491663
Number of first layer input nodes during this epoch:  167727
 full batch blocks save
Number of first layer input nodes during this epoch:  167739
torch.Size([167739, 128])
torch.Size([166687, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.04755234718322754 |0.017572879791259766 |0.007549285888671875 |0.00022673606872558594 |0.0042417049407958984 |0.003522634506225586 |
----------------------------------------------------------pseudo_mini_loss sum 1.3884466886520386
Total dataloading + training time/epoch 1.894170942994737
Training time/epoch 1.8576929569244385
Training time without block to device /epoch 1.8401200771331787
Training time without total dataloading part /epoch 0.015540361404418945
load block tensor time/epoch 0.04755234718322754
block to device time/epoch 0.017572879791259766
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00097 | Loss 1.3884 | Train 0.4554 | Val 0.5054 | Test 0.5329
Number of nodes for computation during this epoch:  491820
Number of first layer input nodes during this epoch:  167739
 full batch blocks save
Number of first layer input nodes during this epoch:  167762
torch.Size([167762, 128])
torch.Size([166718, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.0761709213256836 |0.043422698974609375 |0.0063478946685791016 |0.00019216537475585938 |0.004401683807373047 |0.0028693675994873047 |
----------------------------------------------------------pseudo_mini_loss sum 1.3826191425323486
Total dataloading + training time/epoch 1.894178100994655
Training time/epoch 1.8947200775146484
Training time without block to device /epoch 1.851297378540039
Training time without total dataloading part /epoch 0.013811111450195312
load block tensor time/epoch 0.0761709213256836
block to device time/epoch 0.043422698974609375
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00098 | Loss 1.3826 | Train 0.4562 | Val 0.5064 | Test 0.5336
Number of nodes for computation during this epoch:  491836
Number of first layer input nodes during this epoch:  167762
 full batch blocks save
Number of first layer input nodes during this epoch:  167727
torch.Size([167727, 128])
torch.Size([166665, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.03810548782348633 |0.017919063568115234 |0.007616281509399414 |0.00019598007202148438 |0.003874063491821289 |0.0034613609313964844 |
----------------------------------------------------------pseudo_mini_loss sum 1.3785948753356934
Total dataloading + training time/epoch 1.893759224149916
Training time/epoch 1.8526203632354736
Training time without block to device /epoch 1.8347012996673584
Training time without total dataloading part /epoch 0.015147686004638672
load block tensor time/epoch 0.03810548782348633
block to device time/epoch 0.017919063568115234
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00099 | Loss 1.3786 | Train 0.4570 | Val 0.5069 | Test 0.5343
Number of nodes for computation during this epoch:  491788
Number of first layer input nodes during this epoch:  167727
 full batch blocks save
Number of first layer input nodes during this epoch:  167725
torch.Size([167725, 128])
torch.Size([166680, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.10146474838256836 |0.03419804573059082 |0.006150007247924805 |0.00018715858459472656 |0.0044307708740234375 |0.002872467041015625 |
----------------------------------------------------------pseudo_mini_loss sum 1.3733495473861694
Total dataloading + training time/epoch 1.8946684718132019
Training time/epoch 1.984532356262207
Training time without block to device /epoch 1.9503343105316162
Training time without total dataloading part /epoch 0.013640403747558594
load block tensor time/epoch 0.10146474838256836
block to device time/epoch 0.03419804573059082
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00100 | Loss 1.3733 | Train 0.4580 | Val 0.5071 | Test 0.5350
Number of nodes for computation during this epoch:  491740
Number of first layer input nodes during this epoch:  167725
 full batch blocks save
Number of first layer input nodes during this epoch:  167731
torch.Size([167731, 128])
torch.Size([166666, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.027461528778076172 |0.012614011764526367 |0.004809379577636719 |0.00016117095947265625 |0.003968238830566406 |0.002212047576904297 |
----------------------------------------------------------pseudo_mini_loss sum 1.3716709613800049
Total dataloading + training time/epoch 1.8884796860194442
Training time/epoch 1.2695155143737793
Training time without block to device /epoch 1.256901502609253
Training time without total dataloading part /epoch 0.011150836944580078
load block tensor time/epoch 0.027461528778076172
block to device time/epoch 0.012614011764526367
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00101 | Loss 1.3717 | Train 0.4584 | Val 0.5077 | Test 0.5353
Number of nodes for computation during this epoch:  491755
Number of first layer input nodes during this epoch:  167731
 full batch blocks save
Number of first layer input nodes during this epoch:  167767
torch.Size([167767, 128])
torch.Size([166704, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.04476642608642578 |0.021780729293823242 |0.007970094680786133 |0.00023674964904785156 |0.004390716552734375 |0.003326892852783203 |
----------------------------------------------------------pseudo_mini_loss sum 1.3684771060943604
Total dataloading + training time/epoch 1.8850936305289174
Training time/epoch 1.5429871082305908
Training time without block to device /epoch 1.5212063789367676
Training time without total dataloading part /epoch 0.015924453735351562
load block tensor time/epoch 0.04476642608642578
block to device time/epoch 0.021780729293823242
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00102 | Loss 1.3685 | Train 0.4590 | Val 0.5084 | Test 0.5359
Number of nodes for computation during this epoch:  491831
Number of first layer input nodes during this epoch:  167767
 full batch blocks save
Number of first layer input nodes during this epoch:  167751
torch.Size([167751, 128])
torch.Size([166664, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.028166770935058594 |0.012274742126464844 |0.005210399627685547 |0.00016188621520996094 |0.0037500858306884766 |0.0027923583984375 |
----------------------------------------------------------pseudo_mini_loss sum 1.3676767349243164
Total dataloading + training time/epoch 1.8795038519553768
Training time/epoch 1.3092567920684814
Training time without block to device /epoch 1.2969820499420166
Training time without total dataloading part /epoch 0.011914730072021484
load block tensor time/epoch 0.028166770935058594
block to device time/epoch 0.012274742126464844
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00103 | Loss 1.3677 | Train 0.4597 | Val 0.5090 | Test 0.5363
Number of nodes for computation during this epoch:  491836
Number of first layer input nodes during this epoch:  167751
 full batch blocks save
Number of first layer input nodes during this epoch:  167749
torch.Size([167749, 128])
torch.Size([166674, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.027755260467529297 |0.013499736785888672 |0.0053386688232421875 |0.0001761913299560547 |0.004014492034912109 |0.0028891563415527344 |
----------------------------------------------------------pseudo_mini_loss sum 1.3606184720993042
Total dataloading + training time/epoch 1.8738226982263417
Training time/epoch 1.2885754108428955
Training time without block to device /epoch 1.2750756740570068
Training time without total dataloading part /epoch 0.012418508529663086
load block tensor time/epoch 0.027755260467529297
block to device time/epoch 0.013499736785888672
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00104 | Loss 1.3606 | Train 0.4601 | Val 0.5097 | Test 0.5369
Number of nodes for computation during this epoch:  491712
Number of first layer input nodes during this epoch:  167749
 full batch blocks save
Number of first layer input nodes during this epoch:  167752
torch.Size([167752, 128])
torch.Size([166665, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.0393526554107666 |0.01589655876159668 |0.005359172821044922 |0.00017023086547851562 |0.004166841506958008 |0.002968311309814453 |
----------------------------------------------------------pseudo_mini_loss sum 1.363645315170288
Total dataloading + training time/epoch 1.868625057311285
Training time/epoch 1.327981948852539
Training time without block to device /epoch 1.3120853900909424
Training time without total dataloading part /epoch 0.012664556503295898
load block tensor time/epoch 0.0393526554107666
block to device time/epoch 0.01589655876159668
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00105 | Loss 1.3636 | Train 0.4604 | Val 0.5099 | Test 0.5372
Number of nodes for computation during this epoch:  491722
Number of first layer input nodes during this epoch:  167752
 full batch blocks save
Number of first layer input nodes during this epoch:  167762
torch.Size([167762, 128])
torch.Size([166705, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.029563426971435547 |0.012022972106933594 |0.00523686408996582 |0.0001633167266845703 |0.0038712024688720703 |0.0027382373809814453 |
----------------------------------------------------------pseudo_mini_loss sum 1.350359559059143
Total dataloading + training time/epoch 1.8627251971442744
Training time/epoch 1.243149757385254
Training time without block to device /epoch 1.2311267852783203
Training time without total dataloading part /epoch 0.012009620666503906
load block tensor time/epoch 0.029563426971435547
block to device time/epoch 0.012022972106933594
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00106 | Loss 1.3504 | Train 0.4606 | Val 0.5101 | Test 0.5373
Number of nodes for computation during this epoch:  491771
Number of first layer input nodes during this epoch:  167762
 full batch blocks save
Number of first layer input nodes during this epoch:  167727
torch.Size([167727, 128])
torch.Size([166658, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.02961564064025879 |0.01185464859008789 |0.005284309387207031 |0.0001857280731201172 |0.004084110260009766 |0.0027818679809570312 |
----------------------------------------------------------pseudo_mini_loss sum 1.3523679971694946
Total dataloading + training time/epoch 1.8569016634860886
Training time/epoch 1.2395193576812744
Training time without block to device /epoch 1.2276647090911865
Training time without total dataloading part /epoch 0.012336015701293945
load block tensor time/epoch 0.02961564064025879
block to device time/epoch 0.01185464859008789
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00107 | Loss 1.3524 | Train 0.4611 | Val 0.5107 | Test 0.5376
Number of nodes for computation during this epoch:  491790
Number of first layer input nodes during this epoch:  167727
 full batch blocks save
Number of first layer input nodes during this epoch:  167721
torch.Size([167721, 128])
torch.Size([166649, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.02801513671875 |0.011965513229370117 |0.0052280426025390625 |0.0001614093780517578 |0.004082441329956055 |0.002775430679321289 |
----------------------------------------------------------pseudo_mini_loss sum 1.3462474346160889
Total dataloading + training time/epoch 1.8512246939871047
Training time/epoch 1.243701696395874
Training time without block to device /epoch 1.231736183166504
Training time without total dataloading part /epoch 0.012247323989868164
load block tensor time/epoch 0.02801513671875
block to device time/epoch 0.011965513229370117
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00108 | Loss 1.3462 | Train 0.4616 | Val 0.5110 | Test 0.5380
Number of nodes for computation during this epoch:  491705
Number of first layer input nodes during this epoch:  167721
 full batch blocks save
Number of first layer input nodes during this epoch:  167745
torch.Size([167745, 128])
torch.Size([166686, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.02805328369140625 |0.012306928634643555 |0.005372524261474609 |0.00016736984252929688 |0.0042498111724853516 |0.003069162368774414 |
----------------------------------------------------------pseudo_mini_loss sum 1.349859356880188
Total dataloading + training time/epoch 1.8459352637649675
Training time/epoch 1.2745869159698486
Training time without block to device /epoch 1.262279987335205
Training time without total dataloading part /epoch 0.012858867645263672
load block tensor time/epoch 0.02805328369140625
block to device time/epoch 0.012306928634643555
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00109 | Loss 1.3499 | Train 0.4621 | Val 0.5114 | Test 0.5384
Number of nodes for computation during this epoch:  491764
Number of first layer input nodes during this epoch:  167745
 full batch blocks save
Number of first layer input nodes during this epoch:  167730
torch.Size([167730, 128])
torch.Size([166657, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.02795553207397461 |0.012098312377929688 |0.005272388458251953 |0.0001766681671142578 |0.0041351318359375 |0.0029354095458984375 |
----------------------------------------------------------pseudo_mini_loss sum 1.346564531326294
Total dataloading + training time/epoch 1.8409962567416105
Training time/epoch 1.3025548458099365
Training time without block to device /epoch 1.2904565334320068
Training time without total dataloading part /epoch 0.012519598007202148
load block tensor time/epoch 0.02795553207397461
block to device time/epoch 0.012098312377929688
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00110 | Loss 1.3466 | Train 0.4625 | Val 0.5121 | Test 0.5387
Number of nodes for computation during this epoch:  491718
Number of first layer input nodes during this epoch:  167730
 full batch blocks save
Number of first layer input nodes during this epoch:  167766
torch.Size([167766, 128])
torch.Size([166669, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.02860856056213379 |0.011584758758544922 |0.00519251823425293 |0.0001761913299560547 |0.00396275520324707 |0.0027642250061035156 |
----------------------------------------------------------pseudo_mini_loss sum 1.3379236459732056
Total dataloading + training time/epoch 1.8357027199891236
Training time/epoch 1.2533254623413086
Training time without block to device /epoch 1.2417407035827637
Training time without total dataloading part /epoch 0.01209568977355957
load block tensor time/epoch 0.02860856056213379
block to device time/epoch 0.011584758758544922
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00111 | Loss 1.3379 | Train 0.4628 | Val 0.5127 | Test 0.5393
Number of nodes for computation during this epoch:  491761
Number of first layer input nodes during this epoch:  167766
 full batch blocks save
Number of first layer input nodes during this epoch:  167765
torch.Size([167765, 128])
torch.Size([166718, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.028598546981811523 |0.012387514114379883 |0.005367755889892578 |0.0001819133758544922 |0.004017353057861328 |0.002820253372192383 |
----------------------------------------------------------pseudo_mini_loss sum 1.338164210319519
Total dataloading + training time/epoch 1.830881227340017
Training time/epoch 1.2956054210662842
Training time without block to device /epoch 1.2832179069519043
Training time without total dataloading part /epoch 0.012387275695800781
load block tensor time/epoch 0.028598546981811523
block to device time/epoch 0.012387514114379883
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00112 | Loss 1.3382 | Train 0.4631 | Val 0.5128 | Test 0.5396
Number of nodes for computation during this epoch:  491895
Number of first layer input nodes during this epoch:  167765
 full batch blocks save
Number of first layer input nodes during this epoch:  167736
torch.Size([167736, 128])
torch.Size([166645, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.029710769653320312 |0.013787984848022461 |0.004662036895751953 |0.00013780593872070312 |0.004172086715698242 |0.0022788047790527344 |
----------------------------------------------------------pseudo_mini_loss sum 1.3335667848587036
Total dataloading + training time/epoch 1.825724857043376
Training time/epoch 1.2481253147125244
Training time without block to device /epoch 1.234337329864502
Training time without total dataloading part /epoch 0.011250734329223633
load block tensor time/epoch 0.029710769653320312
block to device time/epoch 0.013787984848022461
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00113 | Loss 1.3336 | Train 0.4638 | Val 0.5131 | Test 0.5399
Number of nodes for computation during this epoch:  491704
Number of first layer input nodes during this epoch:  167736
 full batch blocks save
Number of first layer input nodes during this epoch:  167739
torch.Size([167739, 128])
torch.Size([166671, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.03014540672302246 |0.014134407043457031 |0.00485682487487793 |0.00018787384033203125 |0.004180192947387695 |0.002232789993286133 |
----------------------------------------------------------pseudo_mini_loss sum 1.3294631242752075
Total dataloading + training time/epoch 1.8203496682016473
Training time/epoch 1.2128667831420898
Training time without block to device /epoch 1.1987323760986328
Training time without total dataloading part /epoch 0.011457681655883789
load block tensor time/epoch 0.03014540672302246
block to device time/epoch 0.014134407043457031
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00114 | Loss 1.3295 | Train 0.4642 | Val 0.5137 | Test 0.5403
Number of nodes for computation during this epoch:  491762
Number of first layer input nodes during this epoch:  167739
 full batch blocks save
Number of first layer input nodes during this epoch:  167781
torch.Size([167781, 128])
torch.Size([166714, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.029270172119140625 |0.011680126190185547 |0.004544496536254883 |0.0001366138458251953 |0.003702878952026367 |0.0020775794982910156 |
----------------------------------------------------------pseudo_mini_loss sum 1.3271992206573486
Total dataloading + training time/epoch 1.815167116082233
Training time/epoch 1.224271535873413
Training time without block to device /epoch 1.2125914096832275
Training time without total dataloading part /epoch 0.010461568832397461
load block tensor time/epoch 0.029270172119140625
block to device time/epoch 0.011680126190185547
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00115 | Loss 1.3272 | Train 0.4650 | Val 0.5146 | Test 0.5405
Number of nodes for computation during this epoch:  491859
Number of first layer input nodes during this epoch:  167781
 full batch blocks save
Number of first layer input nodes during this epoch:  167783
torch.Size([167783, 128])
torch.Size([166708, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.028189659118652344 |0.012720823287963867 |0.005377292633056641 |0.00017070770263671875 |0.003904581069946289 |0.0028192996978759766 |
----------------------------------------------------------pseudo_mini_loss sum 1.3303248882293701
Total dataloading + training time/epoch 1.82939796201114
Training time/epoch 3.465859889984131
Training time without block to device /epoch 3.453139066696167
Training time without total dataloading part /epoch 0.012271881103515625
load block tensor time/epoch 0.028189659118652344
block to device time/epoch 0.012720823287963867
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00116 | Loss 1.3303 | Train 0.4655 | Val 0.5148 | Test 0.5411
Number of nodes for computation during this epoch:  491903
Number of first layer input nodes during this epoch:  167783
 full batch blocks save
Number of first layer input nodes during this epoch:  167739
torch.Size([167739, 128])
torch.Size([166667, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.028702497482299805 |0.013781547546386719 |0.004689216613769531 |0.00014781951904296875 |0.004040956497192383 |0.002111196517944336 |
----------------------------------------------------------pseudo_mini_loss sum 1.3176257610321045
Total dataloading + training time/epoch 1.8496302580222106
Training time/epoch 4.1964898109436035
Training time without block to device /epoch 4.182708263397217
Training time without total dataloading part /epoch 0.010989189147949219
load block tensor time/epoch 0.028702497482299805
block to device time/epoch 0.013781547546386719
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00117 | Loss 1.3176 | Train 0.4663 | Val 0.5154 | Test 0.5418
Number of nodes for computation during this epoch:  491707
Number of first layer input nodes during this epoch:  167739
 full batch blocks save
Number of first layer input nodes during this epoch:  167749
torch.Size([167749, 128])
torch.Size([166682, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.02353835105895996 |0.012874364852905273 |0.005296945571899414 |0.00018453598022460938 |0.00399017333984375 |0.0029320716857910156 |
----------------------------------------------------------pseudo_mini_loss sum 1.31756591796875
Total dataloading + training time/epoch 1.8450851278789973
Training time/epoch 1.3132166862487793
Training time without block to device /epoch 1.300342321395874
Training time without total dataloading part /epoch 0.012403726577758789
load block tensor time/epoch 0.02353835105895996
block to device time/epoch 0.012874364852905273
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00118 | Loss 1.3176 | Train 0.4668 | Val 0.5157 | Test 0.5424
Number of nodes for computation during this epoch:  491808
Number of first layer input nodes during this epoch:  167749
 full batch blocks save
Number of first layer input nodes during this epoch:  167712
torch.Size([167712, 128])
torch.Size([166625, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.02533578872680664 |0.012642860412597656 |0.004732847213745117 |0.00014925003051757812 |0.003943443298339844 |0.0021517276763916016 |
----------------------------------------------------------pseudo_mini_loss sum 1.3117449283599854
Total dataloading + training time/epoch 1.840700626373291
Training time/epoch 1.323240041732788
Training time without block to device /epoch 1.3105971813201904
Training time without total dataloading part /epoch 0.01097726821899414
load block tensor time/epoch 0.02533578872680664
block to device time/epoch 0.012642860412597656
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00119 | Loss 1.3117 | Train 0.4675 | Val 0.5163 | Test 0.5431
Number of nodes for computation during this epoch:  491682
Number of first layer input nodes during this epoch:  167712
 full batch blocks save
Number of first layer input nodes during this epoch:  167756
torch.Size([167756, 128])
torch.Size([166708, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.034653425216674805 |0.015358209609985352 |0.004629611968994141 |0.0001475811004638672 |0.004071712493896484 |0.002138853073120117 |
----------------------------------------------------------pseudo_mini_loss sum 1.3071004152297974
Total dataloading + training time/epoch 1.8360808849334718
Training time/epoch 1.2862441539764404
Training time without block to device /epoch 1.270885944366455
Training time without total dataloading part /epoch 0.01098775863647461
load block tensor time/epoch 0.034653425216674805
block to device time/epoch 0.015358209609985352
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00120 | Loss 1.3071 | Train 0.4682 | Val 0.5166 | Test 0.5436
Number of nodes for computation during this epoch:  491774
Number of first layer input nodes during this epoch:  167756
 full batch blocks save
Number of first layer input nodes during this epoch:  167738
torch.Size([167738, 128])
torch.Size([166658, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.029325008392333984 |0.013987541198730469 |0.005242824554443359 |0.00016307830810546875 |0.003969430923461914 |0.0028383731842041016 |
----------------------------------------------------------pseudo_mini_loss sum 1.3056977987289429
Total dataloading + training time/epoch 1.8316966186870227
Training time/epoch 1.3054959774017334
Training time without block to device /epoch 1.291508436203003
Training time without total dataloading part /epoch 0.012213706970214844
load block tensor time/epoch 0.029325008392333984
block to device time/epoch 0.013987541198730469
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00121 | Loss 1.3057 | Train 0.4684 | Val 0.5170 | Test 0.5440
Number of nodes for computation during this epoch:  491736
Number of first layer input nodes during this epoch:  167738
 full batch blocks save
Number of first layer input nodes during this epoch:  167757
torch.Size([167757, 128])
torch.Size([166696, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.029924631118774414 |0.01251530647277832 |0.004732608795166016 |0.00016808509826660156 |0.00382232666015625 |0.002224445343017578 |
----------------------------------------------------------pseudo_mini_loss sum 1.3043060302734375
Total dataloading + training time/epoch 1.8267533329666639
Training time/epoch 1.2285306453704834
Training time without block to device /epoch 1.216015338897705
Training time without total dataloading part /epoch 0.010947465896606445
load block tensor time/epoch 0.029924631118774414
block to device time/epoch 0.01251530647277832
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00122 | Loss 1.3043 | Train 0.4687 | Val 0.5173 | Test 0.5443
Number of nodes for computation during this epoch:  491830
Number of first layer input nodes during this epoch:  167757
 full batch blocks save
Number of first layer input nodes during this epoch:  167795
torch.Size([167795, 128])
torch.Size([166705, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.03013920783996582 |0.011632919311523438 |0.004628896713256836 |0.00014090538024902344 |0.00368499755859375 |0.0021691322326660156 |
----------------------------------------------------------pseudo_mini_loss sum 1.3013538122177124
Total dataloading + training time/epoch 1.8216350039815514
Training time/epoch 1.1971123218536377
Training time without block to device /epoch 1.1854794025421143
Training time without total dataloading part /epoch 0.010623931884765625
load block tensor time/epoch 0.03013920783996582
block to device time/epoch 0.011632919311523438
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00123 | Loss 1.3014 | Train 0.4691 | Val 0.5175 | Test 0.5442
Number of nodes for computation during this epoch:  491864
Number of first layer input nodes during this epoch:  167795
 full batch blocks save
Number of first layer input nodes during this epoch:  167734
torch.Size([167734, 128])
torch.Size([166685, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.029403209686279297 |0.027582406997680664 |0.004963397979736328 |0.00015592575073242188 |0.0042803287506103516 |0.002195119857788086 |
----------------------------------------------------------pseudo_mini_loss sum 1.3013638257980347
Total dataloading + training time/epoch 1.8174822657339034
Training time/epoch 1.3066058158874512
Training time without block to device /epoch 1.2790234088897705
Training time without total dataloading part /epoch 0.011594772338867188
load block tensor time/epoch 0.029403209686279297
block to device time/epoch 0.027582406997680664
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00124 | Loss 1.3014 | Train 0.4694 | Val 0.5176 | Test 0.5441
Number of nodes for computation during this epoch:  491754
Number of first layer input nodes during this epoch:  167734
 full batch blocks save
Number of first layer input nodes during this epoch:  167725
torch.Size([167725, 128])
torch.Size([166626, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.030148029327392578 |0.013840198516845703 |0.004671573638916016 |0.00014519691467285156 |0.004003286361694336 |0.0021317005157470703 |
----------------------------------------------------------pseudo_mini_loss sum 1.2992874383926392
Total dataloading + training time/epoch 1.8130712203979493
Training time/epoch 1.2660167217254639
Training time without block to device /epoch 1.2521765232086182
Training time without total dataloading part /epoch 0.010951757431030273
load block tensor time/epoch 0.030148029327392578
block to device time/epoch 0.013840198516845703
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00125 | Loss 1.2993 | Train 0.4696 | Val 0.5177 | Test 0.5437
Number of nodes for computation during this epoch:  491749
Number of first layer input nodes during this epoch:  167725
 full batch blocks save
Number of first layer input nodes during this epoch:  167776
torch.Size([167776, 128])
torch.Size([166702, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.029660701751708984 |0.012421846389770508 |0.004653453826904297 |0.00014638900756835938 |0.003948211669921875 |0.0021719932556152344 |
----------------------------------------------------------pseudo_mini_loss sum 1.295337438583374
Total dataloading + training time/epoch 1.8084614049820673
Training time/epoch 1.2321462631225586
Training time without block to device /epoch 1.219724416732788
Training time without total dataloading part /epoch 0.010920047760009766
load block tensor time/epoch 0.029660701751708984
block to device time/epoch 0.012421846389770508
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00126 | Loss 1.2953 | Train 0.4698 | Val 0.5178 | Test 0.5437
Number of nodes for computation during this epoch:  491787
Number of first layer input nodes during this epoch:  167776
 full batch blocks save
Number of first layer input nodes during this epoch:  167727
torch.Size([167727, 128])
torch.Size([166683, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.04005932807922363 |0.015702247619628906 |0.0052411556243896484 |0.00018715858459472656 |0.004030942916870117 |0.002203702926635742 |
----------------------------------------------------------pseudo_mini_loss sum 1.2871527671813965
Total dataloading + training time/epoch 1.8048228898386316
Training time/epoch 1.34627366065979
Training time without block to device /epoch 1.3305714130401611
Training time without total dataloading part /epoch 0.011662960052490234
load block tensor time/epoch 0.04005932807922363
block to device time/epoch 0.015702247619628906
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00127 | Loss 1.2872 | Train 0.4700 | Val 0.5176 | Test 0.5437
Number of nodes for computation during this epoch:  491776
Number of first layer input nodes during this epoch:  167727
 full batch blocks save
Number of first layer input nodes during this epoch:  167698
torch.Size([167698, 128])
torch.Size([166612, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.029598474502563477 |0.01229548454284668 |0.004553794860839844 |0.00014281272888183594 |0.004065513610839844 |0.002061128616333008 |
----------------------------------------------------------pseudo_mini_loss sum 1.288765549659729
Total dataloading + training time/epoch 1.8008442558348179
Training time/epoch 1.2954738140106201
Training time without block to device /epoch 1.2831783294677734
Training time without total dataloading part /epoch 0.010823249816894531
load block tensor time/epoch 0.029598474502563477
block to device time/epoch 0.01229548454284668
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00128 | Loss 1.2888 | Train 0.4700 | Val 0.5182 | Test 0.5438
Number of nodes for computation during this epoch:  491671
Number of first layer input nodes during this epoch:  167698
 full batch blocks save
Number of first layer input nodes during this epoch:  167782
torch.Size([167782, 128])
torch.Size([166714, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.02968287467956543 |0.012329578399658203 |0.004775524139404297 |0.0001614093780517578 |0.004116058349609375 |0.002171039581298828 |
----------------------------------------------------------pseudo_mini_loss sum 1.2867404222488403
Total dataloading + training time/epoch 1.796503414479337
Training time/epoch 1.2407891750335693
Training time without block to device /epoch 1.2284595966339111
Training time without total dataloading part /epoch 0.011224031448364258
load block tensor time/epoch 0.02968287467956543
block to device time/epoch 0.012329578399658203
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00129 | Loss 1.2867 | Train 0.4701 | Val 0.5182 | Test 0.5438
Number of nodes for computation during this epoch:  491881
Number of first layer input nodes during this epoch:  167782
 full batch blocks save
Number of first layer input nodes during this epoch:  167729
torch.Size([167729, 128])
torch.Size([166661, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.03956341743469238 |0.015058040618896484 |0.0050506591796875 |0.00017142295837402344 |0.004008769989013672 |0.002257108688354492 |
----------------------------------------------------------pseudo_mini_loss sum 1.2854516506195068
Total dataloading + training time/epoch 1.7926658355272733
Training time/epoch 1.2975242137908936
Training time without block to device /epoch 1.282466173171997
Training time without total dataloading part /epoch 0.011487960815429688
load block tensor time/epoch 0.03956341743469238
block to device time/epoch 0.015058040618896484
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00130 | Loss 1.2855 | Train 0.4703 | Val 0.5182 | Test 0.5439
Number of nodes for computation during this epoch:  491764
Number of first layer input nodes during this epoch:  167729
 full batch blocks save
Number of first layer input nodes during this epoch:  167749
torch.Size([167749, 128])
torch.Size([166693, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.028287410736083984 |0.01233983039855957 |0.004569530487060547 |0.00014138221740722656 |0.003918886184692383 |0.0020546913146972656 |
----------------------------------------------------------pseudo_mini_loss sum 1.2823002338409424
Total dataloading + training time/epoch 1.788050746189729
Training time/epoch 1.1880054473876953
Training time without block to device /epoch 1.1756656169891357
Training time without total dataloading part /epoch 0.010684490203857422
load block tensor time/epoch 0.028287410736083984
block to device time/epoch 0.01233983039855957
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00131 | Loss 1.2823 | Train 0.4705 | Val 0.5184 | Test 0.5438
Number of nodes for computation during this epoch:  491770
Number of first layer input nodes during this epoch:  167749
 full batch blocks save
Number of first layer input nodes during this epoch:  167744
torch.Size([167744, 128])
torch.Size([166658, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.030382394790649414 |0.012774467468261719 |0.005553007125854492 |0.00019311904907226562 |0.004129648208618164 |0.003506183624267578 |
----------------------------------------------------------pseudo_mini_loss sum 1.2748935222625732
Total dataloading + training time/epoch 1.7847299774487813
Training time/epoch 1.3496208190917969
Training time without block to device /epoch 1.3368463516235352
Training time without total dataloading part /epoch 0.0133819580078125
load block tensor time/epoch 0.030382394790649414
block to device time/epoch 0.012774467468261719
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00132 | Loss 1.2749 | Train 0.4709 | Val 0.5186 | Test 0.5441
Number of nodes for computation during this epoch:  491744
Number of first layer input nodes during this epoch:  167744
 full batch blocks save
Number of first layer input nodes during this epoch:  167735
torch.Size([167735, 128])
torch.Size([166656, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.04039788246154785 |0.01434636116027832 |0.004761219024658203 |0.0001475811004638672 |0.003884553909301758 |0.002135753631591797 |
----------------------------------------------------------pseudo_mini_loss sum 1.2759767770767212
Total dataloading + training time/epoch 1.7812587856350088
Training time/epoch 1.3229780197143555
Training time without block to device /epoch 1.3086316585540771
Training time without total dataloading part /epoch 0.010929107666015625
load block tensor time/epoch 0.04039788246154785
block to device time/epoch 0.01434636116027832
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00133 | Loss 1.2760 | Train 0.4712 | Val 0.5186 | Test 0.5442
Number of nodes for computation during this epoch:  491727
Number of first layer input nodes during this epoch:  167735
 full batch blocks save
Number of first layer input nodes during this epoch:  167743
torch.Size([167743, 128])
torch.Size([166652, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.029612064361572266 |0.011632442474365234 |0.004634380340576172 |0.0001423358917236328 |0.0038428306579589844 |0.002238035202026367 |
----------------------------------------------------------pseudo_mini_loss sum 1.2760909795761108
Total dataloading + training time/epoch 1.776815400194766
Training time/epoch 1.185760498046875
Training time without block to device /epoch 1.1741280555725098
Training time without total dataloading part /epoch 0.010857582092285156
load block tensor time/epoch 0.029612064361572266
block to device time/epoch 0.011632442474365234
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00134 | Loss 1.2761 | Train 0.4714 | Val 0.5186 | Test 0.5444
Number of nodes for computation during this epoch:  491693
Number of first layer input nodes during this epoch:  167743
 full batch blocks save
Number of first layer input nodes during this epoch:  167751
torch.Size([167751, 128])
torch.Size([166723, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.0283358097076416 |0.011899471282958984 |0.004977226257324219 |0.00016236305236816406 |0.004103899002075195 |0.0022499561309814453 |
----------------------------------------------------------pseudo_mini_loss sum 1.2714591026306152
Total dataloading + training time/epoch 1.7729884253607855
Training time/epoch 1.2600858211517334
Training time without block to device /epoch 1.2481863498687744
Training time without total dataloading part /epoch 0.011493444442749023
load block tensor time/epoch 0.0283358097076416
block to device time/epoch 0.011899471282958984
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00135 | Loss 1.2715 | Train 0.4717 | Val 0.5187 | Test 0.5447
Number of nodes for computation during this epoch:  491868
Number of first layer input nodes during this epoch:  167751
 full batch blocks save
Number of first layer input nodes during this epoch:  167749
torch.Size([167749, 128])
torch.Size([166630, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.028014421463012695 |0.011568546295166016 |0.004643678665161133 |0.00014090538024902344 |0.003918170928955078 |0.0021109580993652344 |
----------------------------------------------------------pseudo_mini_loss sum 1.269923448562622
Total dataloading + training time/epoch 1.7686086209381329
Training time/epoch 1.1772489547729492
Training time without block to device /epoch 1.1656804084777832
Training time without total dataloading part /epoch 0.010813713073730469
load block tensor time/epoch 0.028014421463012695
block to device time/epoch 0.011568546295166016
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00136 | Loss 1.2699 | Train 0.4723 | Val 0.5189 | Test 0.5450
Number of nodes for computation during this epoch:  491682
Number of first layer input nodes during this epoch:  167749
 full batch blocks save
Number of first layer input nodes during this epoch:  167745
torch.Size([167745, 128])
torch.Size([166680, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.03815507888793945 |0.018674373626708984 |0.00806736946105957 |0.00022292137145996094 |0.0041806697845458984 |0.003645658493041992 |
----------------------------------------------------------pseudo_mini_loss sum 1.2667292356491089
Total dataloading + training time/epoch 1.767205121743418
Training time/epoch 1.5762250423431396
Training time without block to device /epoch 1.5575506687164307
Training time without total dataloading part /epoch 0.016116619110107422
load block tensor time/epoch 0.03815507888793945
block to device time/epoch 0.018674373626708984
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00137 | Loss 1.2667 | Train 0.4728 | Val 0.5192 | Test 0.5452
Number of nodes for computation during this epoch:  491748
Number of first layer input nodes during this epoch:  167745
 full batch blocks save
Number of first layer input nodes during this epoch:  167740
torch.Size([167740, 128])
torch.Size([166664, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.041205644607543945 |0.017271041870117188 |0.0046808719635009766 |0.00015211105346679688 |0.004220724105834961 |0.00212860107421875 |
----------------------------------------------------------pseudo_mini_loss sum 1.2599878311157227
Total dataloading + training time/epoch 1.7635180362756702
Training time/epoch 1.2583036422729492
Training time without block to device /epoch 1.241032600402832
Training time without total dataloading part /epoch 0.011182308197021484
load block tensor time/epoch 0.041205644607543945
block to device time/epoch 0.017271041870117188
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00138 | Loss 1.2600 | Train 0.4728 | Val 0.5192 | Test 0.5456
Number of nodes for computation during this epoch:  491728
Number of first layer input nodes during this epoch:  167740
 full batch blocks save
Number of first layer input nodes during this epoch:  167724
torch.Size([167724, 128])
torch.Size([166644, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.02797842025756836 |0.0113983154296875 |0.004622459411621094 |0.00014138221740722656 |0.0038645267486572266 |0.002225160598754883 |
----------------------------------------------------------pseudo_mini_loss sum 1.2565158605575562
Total dataloading + training time/epoch 1.7594880989129595
Training time/epoch 1.2032725811004639
Training time without block to device /epoch 1.1918742656707764
Training time without total dataloading part /epoch 0.01085352897644043
load block tensor time/epoch 0.02797842025756836
block to device time/epoch 0.0113983154296875
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00139 | Loss 1.2565 | Train 0.4731 | Val 0.5195 | Test 0.5458
Number of nodes for computation during this epoch:  491684
Number of first layer input nodes during this epoch:  167724
 full batch blocks save
Number of first layer input nodes during this epoch:  167768
torch.Size([167768, 128])
torch.Size([166705, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.029682159423828125 |0.01876091957092285 |0.0048444271087646484 |0.00016641616821289062 |0.00413966178894043 |0.002195119857788086 |
----------------------------------------------------------pseudo_mini_loss sum 1.2600977420806885
Total dataloading + training time/epoch 1.7554166538374765
Training time/epoch 1.1894004344940186
Training time without block to device /epoch 1.1706395149230957
Training time without total dataloading part /epoch 0.011345624923706055
load block tensor time/epoch 0.029682159423828125
block to device time/epoch 0.01876091957092285
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00140 | Loss 1.2601 | Train 0.4734 | Val 0.5197 | Test 0.5460
Number of nodes for computation during this epoch:  491857
Number of first layer input nodes during this epoch:  167768
 full batch blocks save
Number of first layer input nodes during this epoch:  167777
torch.Size([167777, 128])
torch.Size([166711, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.039579153060913086 |0.012979269027709961 |0.0048236846923828125 |0.00015807151794433594 |0.0036246776580810547 |0.0022780895233154297 |
----------------------------------------------------------pseudo_mini_loss sum 1.2537109851837158
Total dataloading + training time/epoch 1.7522225549035038
Training time/epoch 1.3049638271331787
Training time without block to device /epoch 1.2919845581054688
Training time without total dataloading part /epoch 0.010884523391723633
load block tensor time/epoch 0.039579153060913086
block to device time/epoch 0.012979269027709961
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00141 | Loss 1.2537 | Train 0.4737 | Val 0.5201 | Test 0.5464
Number of nodes for computation during this epoch:  491760
Number of first layer input nodes during this epoch:  167777
 full batch blocks save
Number of first layer input nodes during this epoch:  167727
torch.Size([167727, 128])
torch.Size([166657, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.029635906219482422 |0.012378215789794922 |0.004650115966796875 |0.00014543533325195312 |0.004091024398803711 |0.002223491668701172 |
----------------------------------------------------------pseudo_mini_loss sum 1.257012128829956
Total dataloading + training time/epoch 1.748639899240413
Training time/epoch 1.243401050567627
Training time without block to device /epoch 1.231022834777832
Training time without total dataloading part /epoch 0.011110067367553711
load block tensor time/epoch 0.029635906219482422
block to device time/epoch 0.012378215789794922
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00142 | Loss 1.2570 | Train 0.4742 | Val 0.5202 | Test 0.5468
Number of nodes for computation during this epoch:  491740
Number of first layer input nodes during this epoch:  167727
 full batch blocks save
Number of first layer input nodes during this epoch:  167775
torch.Size([167775, 128])
torch.Size([166733, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.030094146728515625 |0.012178182601928711 |0.004766941070556641 |0.0001494884490966797 |0.30110836029052734 |0.0029227733612060547 |
----------------------------------------------------------pseudo_mini_loss sum 1.25393807888031
Total dataloading + training time/epoch 1.7449041163171088
Training time/epoch 1.2143352031707764
Training time without block to device /epoch 1.2021570205688477
Training time without total dataloading part /epoch 0.3089475631713867
load block tensor time/epoch 0.030094146728515625
block to device time/epoch 0.012178182601928711
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00143 | Loss 1.2539 | Train 0.4743 | Val 0.5206 | Test 0.5469
Number of nodes for computation during this epoch:  491898
Number of first layer input nodes during this epoch:  167775
 full batch blocks save
Number of first layer input nodes during this epoch:  167726
torch.Size([167726, 128])
torch.Size([166658, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.03401994705200195 |0.01295328140258789 |0.006000518798828125 |0.00020241737365722656 |0.0043637752532958984 |0.002858877182006836 |
----------------------------------------------------------pseudo_mini_loss sum 1.247564673423767
Total dataloading + training time/epoch 1.747460161646207
Training time/epoch 2.112823724746704
Training time without block to device /epoch 2.099870443344116
Training time without total dataloading part /epoch 0.013425588607788086
load block tensor time/epoch 0.03401994705200195
block to device time/epoch 0.01295328140258789
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00144 | Loss 1.2476 | Train 0.4745 | Val 0.5206 | Test 0.5469
Number of nodes for computation during this epoch:  491658
Number of first layer input nodes during this epoch:  167726
 full batch blocks save
Number of first layer input nodes during this epoch:  167755
torch.Size([167755, 128])
torch.Size([166686, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.025966882705688477 |0.02599787712097168 |0.004980802536010742 |0.00016307830810546875 |0.004483938217163086 |0.002420186996459961 |
----------------------------------------------------------pseudo_mini_loss sum 1.2413250207901
Total dataloading + training time/epoch 1.7446157126591124
Training time/epoch 1.3349251747131348
Training time without block to device /epoch 1.308927297592163
Training time without total dataloading part /epoch 0.012048006057739258
load block tensor time/epoch 0.025966882705688477
block to device time/epoch 0.02599787712097168
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00145 | Loss 1.2413 | Train 0.4747 | Val 0.5206 | Test 0.5471
Number of nodes for computation during this epoch:  491790
Number of first layer input nodes during this epoch:  167755
 full batch blocks save
Number of first layer input nodes during this epoch:  167760
torch.Size([167760, 128])
torch.Size([166716, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.030565261840820312 |0.012231111526489258 |0.0046770572662353516 |0.0001423358917236328 |0.003968954086303711 |0.002104520797729492 |
----------------------------------------------------------pseudo_mini_loss sum 1.2423341274261475
Total dataloading + training time/epoch 1.742859915511249
Training time/epoch 1.4881832599639893
Training time without block to device /epoch 1.4759521484375
Training time without total dataloading part /epoch 0.010892868041992188
load block tensor time/epoch 0.030565261840820312
block to device time/epoch 0.012231111526489258
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00146 | Loss 1.2423 | Train 0.4750 | Val 0.5207 | Test 0.5473
Number of nodes for computation during this epoch:  491892
Number of first layer input nodes during this epoch:  167760
 full batch blocks save
Number of first layer input nodes during this epoch:  167727
torch.Size([167727, 128])
torch.Size([166665, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.02425074577331543 |0.012216806411743164 |0.004540205001831055 |0.00014519691467285156 |0.004118680953979492 |0.0020804405212402344 |
----------------------------------------------------------pseudo_mini_loss sum 1.2421406507492065
Total dataloading + training time/epoch 1.7392676265872256
Training time/epoch 1.214705467224121
Training time without block to device /epoch 1.202488660812378
Training time without total dataloading part /epoch 0.010884523391723633
load block tensor time/epoch 0.02425074577331543
block to device time/epoch 0.012216806411743164
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00147 | Loss 1.2421 | Train 0.4753 | Val 0.5209 | Test 0.5475
Number of nodes for computation during this epoch:  491755
Number of first layer input nodes during this epoch:  167727
 full batch blocks save
Number of first layer input nodes during this epoch:  167757
torch.Size([167757, 128])
torch.Size([166660, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.03551054000854492 |0.012776374816894531 |0.0054280757904052734 |0.000179290771484375 |0.004193782806396484 |0.0029141902923583984 |
----------------------------------------------------------pseudo_mini_loss sum 1.2374285459518433
Total dataloading + training time/epoch 1.7374530563483368
Training time/epoch 1.4706227779388428
Training time without block to device /epoch 1.4578464031219482
Training time without total dataloading part /epoch 0.012715339660644531
load block tensor time/epoch 0.03551054000854492
block to device time/epoch 0.012776374816894531
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00148 | Loss 1.2374 | Train 0.4753 | Val 0.5213 | Test 0.5476
Number of nodes for computation during this epoch:  491770
Number of first layer input nodes during this epoch:  167757
 full batch blocks save
Number of first layer input nodes during this epoch:  167725
torch.Size([167725, 128])
torch.Size([166627, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.025572538375854492 |0.01240682601928711 |0.004663228988647461 |0.00014519691467285156 |0.004169464111328125 |0.0043027400970458984 |
----------------------------------------------------------pseudo_mini_loss sum 1.237363338470459
Total dataloading + training time/epoch 1.7348236205593852
Training time/epoch 1.3455810546875
Training time without block to device /epoch 1.333174228668213
Training time without total dataloading part /epoch 0.013280630111694336
load block tensor time/epoch 0.025572538375854492
block to device time/epoch 0.01240682601928711
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00149 | Loss 1.2374 | Train 0.4754 | Val 0.5215 | Test 0.5477
Number of nodes for computation during this epoch:  491657
Number of first layer input nodes during this epoch:  167725
 full batch blocks save
Number of first layer input nodes during this epoch:  167710
torch.Size([167710, 128])
torch.Size([166666, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.028045177459716797 |0.018687725067138672 |0.005537986755371094 |0.00019097328186035156 |0.0041866302490234375 |0.003017425537109375 |
----------------------------------------------------------pseudo_mini_loss sum 1.2332459688186646
Total dataloading + training time/epoch 1.7322338596979776
Training time/epoch 1.346268892288208
Training time without block to device /epoch 1.3275811672210693
Training time without total dataloading part /epoch 0.012933015823364258
load block tensor time/epoch 0.028045177459716797
block to device time/epoch 0.018687725067138672
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00150 | Loss 1.2332 | Train 0.4756 | Val 0.5215 | Test 0.5478
Number of nodes for computation during this epoch:  491796
Number of first layer input nodes during this epoch:  167710
 full batch blocks save
Number of first layer input nodes during this epoch:  167762
torch.Size([167762, 128])
torch.Size([166680, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.02917790412902832 |0.013216972351074219 |0.004675865173339844 |0.0001475811004638672 |0.003857851028442383 |0.0021295547485351562 |
----------------------------------------------------------pseudo_mini_loss sum 1.2314960956573486
Total dataloading + training time/epoch 1.7292188540199736
Training time/epoch 1.2768807411193848
Training time without block to device /epoch 1.2636637687683105
Training time without total dataloading part /epoch 0.01081085205078125
load block tensor time/epoch 0.02917790412902832
block to device time/epoch 0.013216972351074219
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00151 | Loss 1.2315 | Train 0.4759 | Val 0.5219 | Test 0.5479
Number of nodes for computation during this epoch:  491756
Number of first layer input nodes during this epoch:  167762
 full batch blocks save
Number of first layer input nodes during this epoch:  167702
torch.Size([167702, 128])
torch.Size([166662, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.029683351516723633 |0.012923479080200195 |0.0046710968017578125 |0.00014448165893554688 |0.003972053527832031 |0.002336740493774414 |
----------------------------------------------------------pseudo_mini_loss sum 1.228534460067749
Total dataloading + training time/epoch 1.7257239583291506
Training time/epoch 1.197908878326416
Training time without block to device /epoch 1.1849853992462158
Training time without total dataloading part /epoch 0.011124372482299805
load block tensor time/epoch 0.029683351516723633
block to device time/epoch 0.012923479080200195
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00152 | Loss 1.2285 | Train 0.4760 | Val 0.5221 | Test 0.5479
Number of nodes for computation during this epoch:  491744
Number of first layer input nodes during this epoch:  167702
 full batch blocks save
Number of first layer input nodes during this epoch:  167757
torch.Size([167757, 128])
torch.Size([166670, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.030267715454101562 |0.012364625930786133 |0.004708528518676758 |0.0001590251922607422 |0.0040740966796875 |0.002129077911376953 |
----------------------------------------------------------pseudo_mini_loss sum 1.2270153760910034
Total dataloading + training time/epoch 1.7224879436243594
Training time/epoch 1.230527400970459
Training time without block to device /epoch 1.2181627750396729
Training time without total dataloading part /epoch 0.011070728302001953
load block tensor time/epoch 0.030267715454101562
block to device time/epoch 0.012364625930786133
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00153 | Loss 1.2270 | Train 0.4761 | Val 0.5219 | Test 0.5480
Number of nodes for computation during this epoch:  491745
Number of first layer input nodes during this epoch:  167757
 full batch blocks save
Number of first layer input nodes during this epoch:  167703
torch.Size([167703, 128])
torch.Size([166653, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.029851436614990234 |0.011599302291870117 |0.004647970199584961 |0.00014066696166992188 |0.004002809524536133 |0.0022115707397460938 |
----------------------------------------------------------pseudo_mini_loss sum 1.2257550954818726
Total dataloading + training time/epoch 1.7192300991578535
Training time/epoch 1.220693588256836
Training time without block to device /epoch 1.2090942859649658
Training time without total dataloading part /epoch 0.01100301742553711
load block tensor time/epoch 0.029851436614990234
block to device time/epoch 0.011599302291870117
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00154 | Loss 1.2258 | Train 0.4761 | Val 0.5216 | Test 0.5477
Number of nodes for computation during this epoch:  491660
Number of first layer input nodes during this epoch:  167703
 full batch blocks save
Number of first layer input nodes during this epoch:  167752
torch.Size([167752, 128])
torch.Size([166659, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.029490947723388672 |0.012685775756835938 |0.004735469818115234 |0.0001506805419921875 |0.003988027572631836 |0.002142190933227539 |
----------------------------------------------------------pseudo_mini_loss sum 1.2216771841049194
Total dataloading + training time/epoch 1.717842580426124
Training time/epoch 1.5040779113769531
Training time without block to device /epoch 1.4913921356201172
Training time without total dataloading part /epoch 0.011016368865966797
load block tensor time/epoch 0.029490947723388672
block to device time/epoch 0.012685775756835938
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00155 | Loss 1.2217 | Train 0.4762 | Val 0.5213 | Test 0.5477
Number of nodes for computation during this epoch:  491674
Number of first layer input nodes during this epoch:  167752
 full batch blocks save
Number of first layer input nodes during this epoch:  167732
torch.Size([167732, 128])
torch.Size([166651, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.02904057502746582 |0.020038843154907227 |0.0053250789642333984 |0.0001735687255859375 |0.003993034362792969 |0.002933979034423828 |
----------------------------------------------------------pseudo_mini_loss sum 1.2223312854766846
Total dataloading + training time/epoch 1.7158066844328856
Training time/epoch 1.400153636932373
Training time without block to device /epoch 1.3801147937774658
Training time without total dataloading part /epoch 0.012425661087036133
load block tensor time/epoch 0.02904057502746582
block to device time/epoch 0.020038843154907227
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00156 | Loss 1.2223 | Train 0.4760 | Val 0.5213 | Test 0.5476
Number of nodes for computation during this epoch:  491715
Number of first layer input nodes during this epoch:  167732
 full batch blocks save
Number of first layer input nodes during this epoch:  167722
torch.Size([167722, 128])
torch.Size([166635, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.039374351501464844 |0.013889551162719727 |0.005247592926025391 |0.0001704692840576172 |0.003865957260131836 |0.0030257701873779297 |
----------------------------------------------------------pseudo_mini_loss sum 1.218958854675293
Total dataloading + training time/epoch 1.7134092947480026
Training time/epoch 1.3393268585205078
Training time without block to device /epoch 1.325437307357788
Training time without total dataloading part /epoch 0.012309789657592773
load block tensor time/epoch 0.039374351501464844
block to device time/epoch 0.013889551162719727
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00157 | Loss 1.2190 | Train 0.4756 | Val 0.5207 | Test 0.5471
Number of nodes for computation during this epoch:  491660
Number of first layer input nodes during this epoch:  167722
 full batch blocks save
Number of first layer input nodes during this epoch:  167719
torch.Size([167719, 128])
torch.Size([166656, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.029675006866455078 |0.01233053207397461 |0.005216121673583984 |0.00016307830810546875 |0.00397801399230957 |0.0027627944946289062 |
----------------------------------------------------------pseudo_mini_loss sum 1.2206867933273315
Total dataloading + training time/epoch 1.710628114169157
Training time/epoch 1.2738943099975586
Training time without block to device /epoch 1.261563777923584
Training time without total dataloading part /epoch 0.01212000846862793
load block tensor time/epoch 0.029675006866455078
block to device time/epoch 0.01233053207397461
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00158 | Loss 1.2207 | Train 0.4752 | Val 0.5201 | Test 0.5466
Number of nodes for computation during this epoch:  491745
Number of first layer input nodes during this epoch:  167719
 full batch blocks save
Number of first layer input nodes during this epoch:  167719
torch.Size([167719, 128])
torch.Size([166660, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.02970409393310547 |0.012117862701416016 |0.0053179264068603516 |0.00018405914306640625 |0.004056453704833984 |0.0027997493743896484 |
----------------------------------------------------------pseudo_mini_loss sum 1.2177852392196655
Total dataloading + training time/epoch 1.7074105349726647
Training time/epoch 1.1989450454711914
Training time without block to device /epoch 1.1868271827697754
Training time without total dataloading part /epoch 0.01235818862915039
load block tensor time/epoch 0.02970409393310547
block to device time/epoch 0.012117862701416016
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00159 | Loss 1.2178 | Train 0.4752 | Val 0.5202 | Test 0.5462
Number of nodes for computation during this epoch:  491666
Number of first layer input nodes during this epoch:  167719
 full batch blocks save
Number of first layer input nodes during this epoch:  167692
torch.Size([167692, 128])
torch.Size([166646, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.029493331909179688 |0.011907100677490234 |0.005222797393798828 |0.0001659393310546875 |0.004124879837036133 |0.0029234886169433594 |
----------------------------------------------------------pseudo_mini_loss sum 1.2130390405654907
Total dataloading + training time/epoch 1.704707795381546
Training time/epoch 1.27488374710083
Training time without block to device /epoch 1.2629766464233398
Training time without total dataloading part /epoch 0.012437105178833008
load block tensor time/epoch 0.029493331909179688
block to device time/epoch 0.011907100677490234
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00160 | Loss 1.2130 | Train 0.4753 | Val 0.5198 | Test 0.5462
Number of nodes for computation during this epoch:  491669
Number of first layer input nodes during this epoch:  167692
 full batch blocks save
Number of first layer input nodes during this epoch:  167735
torch.Size([167735, 128])
torch.Size([166694, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.033129215240478516 |0.012528419494628906 |0.004787921905517578 |0.0001537799835205078 |0.004037380218505859 |0.0021462440490722656 |
----------------------------------------------------------pseudo_mini_loss sum 1.2077128887176514
Total dataloading + training time/epoch 1.7017461824120943
Training time/epoch 1.22780179977417
Training time without block to device /epoch 1.215273380279541
Training time without total dataloading part /epoch 0.011125326156616211
load block tensor time/epoch 0.033129215240478516
block to device time/epoch 0.012528419494628906
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00161 | Loss 1.2077 | Train 0.4754 | Val 0.5198 | Test 0.5462
Number of nodes for computation during this epoch:  491694
Number of first layer input nodes during this epoch:  167735
 full batch blocks save
Number of first layer input nodes during this epoch:  167738
torch.Size([167738, 128])
torch.Size([166695, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.028874635696411133 |0.0171053409576416 |0.00594639778137207 |0.0001957416534423828 |0.0043184757232666016 |0.003099679946899414 |
----------------------------------------------------------pseudo_mini_loss sum 1.2115458250045776
Total dataloading + training time/epoch 1.7065634124072981
Training time/epoch 2.4819858074188232
Training time without block to device /epoch 2.4648804664611816
Training time without total dataloading part /epoch 0.013560295104980469
load block tensor time/epoch 0.028874635696411133
block to device time/epoch 0.0171053409576416
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00162 | Loss 1.2115 | Train 0.4755 | Val 0.5203 | Test 0.5463
Number of nodes for computation during this epoch:  491855
Number of first layer input nodes during this epoch:  167738
 full batch blocks save
Number of first layer input nodes during this epoch:  167750
torch.Size([167750, 128])
torch.Size([166705, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.022912979125976562 |0.012095928192138672 |0.005201816558837891 |0.00017690658569335938 |0.003916025161743164 |0.0028634071350097656 |
----------------------------------------------------------pseudo_mini_loss sum 1.2059839963912964
Total dataloading + training time/epoch 1.7042680854446317
Training time/epoch 1.3323352336883545
Training time without block to device /epoch 1.3202393054962158
Training time without total dataloading part /epoch 0.01215815544128418
load block tensor time/epoch 0.022912979125976562
block to device time/epoch 0.012095928192138672
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00163 | Loss 1.2060 | Train 0.4756 | Val 0.5207 | Test 0.5467
Number of nodes for computation during this epoch:  491822
Number of first layer input nodes during this epoch:  167750
 full batch blocks save
Number of first layer input nodes during this epoch:  167726
torch.Size([167726, 128])
torch.Size([166675, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.023400068283081055 |0.013695955276489258 |0.00499272346496582 |0.0001704692840576172 |0.004132747650146484 |0.0023474693298339844 |
----------------------------------------------------------pseudo_mini_loss sum 1.2036844491958618
Total dataloading + training time/epoch 1.7014094009632017
Training time/epoch 1.2353448867797852
Training time without block to device /epoch 1.221648931503296
Training time without total dataloading part /epoch 0.011643409729003906
load block tensor time/epoch 0.023400068283081055
block to device time/epoch 0.013695955276489258
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00164 | Loss 1.2037 | Train 0.4758 | Val 0.5209 | Test 0.5467
Number of nodes for computation during this epoch:  491745
Number of first layer input nodes during this epoch:  167726
 full batch blocks save
Number of first layer input nodes during this epoch:  167706
torch.Size([167706, 128])
torch.Size([166655, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.026790380477905273 |0.016784191131591797 |0.005280494689941406 |0.0001811981201171875 |0.004029989242553711 |0.003026247024536133 |
----------------------------------------------------------pseudo_mini_loss sum 1.2025309801101685
Total dataloading + training time/epoch 1.6994514248587869
Training time/epoch 1.3782544136047363
Training time without block to device /epoch 1.3614702224731445
Training time without total dataloading part /epoch 0.012517929077148438
load block tensor time/epoch 0.026790380477905273
block to device time/epoch 0.016784191131591797
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00165 | Loss 1.2025 | Train 0.4762 | Val 0.5212 | Test 0.5474
Number of nodes for computation during this epoch:  491677
Number of first layer input nodes during this epoch:  167706
 full batch blocks save
Number of first layer input nodes during this epoch:  167730
torch.Size([167730, 128])
torch.Size([166665, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.02644205093383789 |0.012788772583007812 |0.005250215530395508 |0.0001678466796875 |0.003690004348754883 |0.0029745101928710938 |
----------------------------------------------------------pseudo_mini_loss sum 1.2026050090789795
Total dataloading + training time/epoch 1.697236461811755
Training time/epoch 1.3316786289215088
Training time without block to device /epoch 1.318889856338501
Training time without total dataloading part /epoch 0.012082576751708984
load block tensor time/epoch 0.02644205093383789
block to device time/epoch 0.012788772583007812
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00166 | Loss 1.2026 | Train 0.4766 | Val 0.5220 | Test 0.5480
Number of nodes for computation during this epoch:  491671
Number of first layer input nodes during this epoch:  167730
 full batch blocks save
Number of first layer input nodes during this epoch:  167699
torch.Size([167699, 128])
torch.Size([166607, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.0390927791595459 |0.012013435363769531 |0.0055103302001953125 |0.0001895427703857422 |0.003764629364013672 |0.0028028488159179688 |
----------------------------------------------------------pseudo_mini_loss sum 1.1997627019882202
Total dataloading + training time/epoch 1.6950356474893535
Training time/epoch 1.3296101093292236
Training time without block to device /epoch 1.317596673965454
Training time without total dataloading part /epoch 0.012267351150512695
load block tensor time/epoch 0.0390927791595459
block to device time/epoch 0.012013435363769531
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00167 | Loss 1.1998 | Train 0.4769 | Val 0.5229 | Test 0.5488
Number of nodes for computation during this epoch:  491568
Number of first layer input nodes during this epoch:  167699
 full batch blocks save
Number of first layer input nodes during this epoch:  167714
torch.Size([167714, 128])
torch.Size([166646, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.027915000915527344 |0.012060165405273438 |0.0052106380462646484 |0.00016736984252929688 |0.003973722457885742 |0.002774953842163086 |
----------------------------------------------------------pseudo_mini_loss sum 1.190930724143982
Total dataloading + training time/epoch 1.6927293042341869
Training time/epoch 1.3074798583984375
Training time without block to device /epoch 1.295419692993164
Training time without total dataloading part /epoch 0.012126684188842773
load block tensor time/epoch 0.027915000915527344
block to device time/epoch 0.012060165405273438
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00168 | Loss 1.1909 | Train 0.4772 | Val 0.5234 | Test 0.5493
Number of nodes for computation during this epoch:  491673
Number of first layer input nodes during this epoch:  167714
 full batch blocks save
Number of first layer input nodes during this epoch:  167747
torch.Size([167747, 128])
torch.Size([166675, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.030041217803955078 |0.013467073440551758 |0.004819393157958984 |0.0001513957977294922 |0.004076242446899414 |0.002167940139770508 |
----------------------------------------------------------pseudo_mini_loss sum 1.1947098970413208
Total dataloading + training time/epoch 1.69632001741398
Training time/epoch 2.2994582653045654
Training time without block to device /epoch 2.2859911918640137
Training time without total dataloading part /epoch 0.011214971542358398
load block tensor time/epoch 0.030041217803955078
block to device time/epoch 0.013467073440551758
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00169 | Loss 1.1947 | Train 0.4774 | Val 0.5237 | Test 0.5496
Number of nodes for computation during this epoch:  491793
Number of first layer input nodes during this epoch:  167747
 full batch blocks save
Number of first layer input nodes during this epoch:  167763
torch.Size([167763, 128])
torch.Size([166688, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.03871011734008789 |0.01688385009765625 |0.004760265350341797 |0.00015306472778320312 |0.003927707672119141 |0.002193450927734375 |
----------------------------------------------------------pseudo_mini_loss sum 1.1880228519439697
Total dataloading + training time/epoch 1.69402635938981
Training time/epoch 1.3063130378723145
Training time without block to device /epoch 1.2894291877746582
Training time without total dataloading part /epoch 0.011034488677978516
load block tensor time/epoch 0.03871011734008789
block to device time/epoch 0.01688385009765625
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00170 | Loss 1.1880 | Train 0.4774 | Val 0.5236 | Test 0.5496
Number of nodes for computation during this epoch:  491827
Number of first layer input nodes during this epoch:  167763
 full batch blocks save
Number of first layer input nodes during this epoch:  167705
torch.Size([167705, 128])
torch.Size([166666, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.03023838996887207 |0.01259160041809082 |0.004551410675048828 |0.0001418590545654297 |0.003761768341064453 |0.0022590160369873047 |
----------------------------------------------------------pseudo_mini_loss sum 1.196273922920227
Total dataloading + training time/epoch 1.6913108435290598
Training time/epoch 1.229586124420166
Training time without block to device /epoch 1.2169945240020752
Training time without total dataloading part /epoch 0.010714054107666016
load block tensor time/epoch 0.03023838996887207
block to device time/epoch 0.01259160041809082
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00171 | Loss 1.1963 | Train 0.4772 | Val 0.5233 | Test 0.5494
Number of nodes for computation during this epoch:  491650
Number of first layer input nodes during this epoch:  167705
 full batch blocks save
Number of first layer input nodes during this epoch:  167772
torch.Size([167772, 128])
torch.Size([166738, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.029210567474365234 |0.013213396072387695 |0.00467228889465332 |0.000156402587890625 |0.3005189895629883 |0.002155780792236328 |
----------------------------------------------------------pseudo_mini_loss sum 1.1904550790786743
Total dataloading + training time/epoch 1.6888398514237515
Training time/epoch 1.2662153244018555
Training time without block to device /epoch 1.2530019283294678
Training time without total dataloading part /epoch 0.30750346183776855
load block tensor time/epoch 0.029210567474365234
block to device time/epoch 0.013213396072387695
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00172 | Loss 1.1905 | Train 0.4770 | Val 0.5227 | Test 0.5488
Number of nodes for computation during this epoch:  491875
Number of first layer input nodes during this epoch:  167772
 full batch blocks save
Number of first layer input nodes during this epoch:  167761
torch.Size([167761, 128])
torch.Size([166704, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.03918600082397461 |0.018581390380859375 |0.005407810211181641 |0.00018072128295898438 |0.003941535949707031 |0.002370595932006836 |
----------------------------------------------------------pseudo_mini_loss sum 1.1859946250915527
Total dataloading + training time/epoch 1.6868407367970901
Training time/epoch 1.3428521156311035
Training time without block to device /epoch 1.3242707252502441
Training time without total dataloading part /epoch 0.011900663375854492
load block tensor time/epoch 0.03918600082397461
block to device time/epoch 0.018581390380859375
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00173 | Loss 1.1860 | Train 0.4767 | Val 0.5215 | Test 0.5482
Number of nodes for computation during this epoch:  491850
Number of first layer input nodes during this epoch:  167761
 full batch blocks save
Number of first layer input nodes during this epoch:  167752
torch.Size([167752, 128])
torch.Size([166699, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.029163360595703125 |0.012749671936035156 |0.004766225814819336 |0.0001628398895263672 |0.00408172607421875 |0.002414226531982422 |
----------------------------------------------------------pseudo_mini_loss sum 1.1873328685760498
Total dataloading + training time/epoch 1.6845723541303612
Training time/epoch 1.2920560836791992
Training time without block to device /epoch 1.279306411743164
Training time without total dataloading part /epoch 0.011425018310546875
load block tensor time/epoch 0.029163360595703125
block to device time/epoch 0.012749671936035156
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00174 | Loss 1.1873 | Train 0.4765 | Val 0.5208 | Test 0.5475
Number of nodes for computation during this epoch:  491851
Number of first layer input nodes during this epoch:  167752
 full batch blocks save
Number of first layer input nodes during this epoch:  167701
torch.Size([167701, 128])
torch.Size([166635, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.029703378677368164 |0.015326976776123047 |0.004775285720825195 |0.00014925003051757812 |0.004042387008666992 |0.002114534378051758 |
----------------------------------------------------------pseudo_mini_loss sum 1.1803516149520874
Total dataloading + training time/epoch 1.6822483226231166
Training time/epoch 1.2777812480926514
Training time without block to device /epoch 1.2624542713165283
Training time without total dataloading part /epoch 0.011081457138061523
load block tensor time/epoch 0.029703378677368164
block to device time/epoch 0.015326976776123047
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00175 | Loss 1.1804 | Train 0.4764 | Val 0.5207 | Test 0.5472
Number of nodes for computation during this epoch:  491676
Number of first layer input nodes during this epoch:  167701
 full batch blocks save
Number of first layer input nodes during this epoch:  167753
torch.Size([167753, 128])
torch.Size([166684, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.03702425956726074 |0.016287803649902344 |0.005425214767456055 |0.00018167495727539062 |0.004312753677368164 |0.003099679946899414 |
----------------------------------------------------------pseudo_mini_loss sum 1.181618571281433
Total dataloading + training time/epoch 1.680484800176187
Training time/epoch 1.371778964996338
Training time without block to device /epoch 1.3554911613464355
Training time without total dataloading part /epoch 0.013019323348999023
load block tensor time/epoch 0.03702425956726074
block to device time/epoch 0.016287803649902344
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00176 | Loss 1.1816 | Train 0.4766 | Val 0.5200 | Test 0.5468
Number of nodes for computation during this epoch:  491797
Number of first layer input nodes during this epoch:  167753
 full batch blocks save
Number of first layer input nodes during this epoch:  167741
torch.Size([167741, 128])
torch.Size([166652, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.036397457122802734 |0.014266014099121094 |0.004714488983154297 |0.0001480579376220703 |0.004330158233642578 |0.0021867752075195312 |
----------------------------------------------------------pseudo_mini_loss sum 1.1834218502044678
Total dataloading + training time/epoch 1.6781897854670293
Training time/epoch 1.2741808891296387
Training time without block to device /epoch 1.2599148750305176
Training time without total dataloading part /epoch 0.011379480361938477
load block tensor time/epoch 0.036397457122802734
block to device time/epoch 0.014266014099121094
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00177 | Loss 1.1834 | Train 0.4767 | Val 0.5199 | Test 0.5465
Number of nodes for computation during this epoch:  491747
Number of first layer input nodes during this epoch:  167741
 full batch blocks save
Number of first layer input nodes during this epoch:  167702
torch.Size([167702, 128])
torch.Size([166644, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.026820898056030273 |0.012955427169799805 |0.005310773849487305 |0.00018644332885742188 |0.0042612552642822266 |0.0027687549591064453 |
----------------------------------------------------------pseudo_mini_loss sum 1.1746724843978882
Total dataloading + training time/epoch 1.6763268119833443
Training time/epoch 1.3464899063110352
Training time without block to device /epoch 1.3335344791412354
Training time without total dataloading part /epoch 0.012527227401733398
load block tensor time/epoch 0.026820898056030273
block to device time/epoch 0.012955427169799805
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00178 | Loss 1.1747 | Train 0.4771 | Val 0.5203 | Test 0.5466
Number of nodes for computation during this epoch:  491642
Number of first layer input nodes during this epoch:  167702
 full batch blocks save
Number of first layer input nodes during this epoch:  167726
torch.Size([167726, 128])
torch.Size([166703, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.02754068374633789 |0.012707948684692383 |0.0045969486236572266 |0.0001461505889892578 |0.003963947296142578 |0.005780458450317383 |
----------------------------------------------------------pseudo_mini_loss sum 1.1756895780563354
Total dataloading + training time/epoch 1.6736656700432633
Training time/epoch 1.1998968124389648
Training time without block to device /epoch 1.1871888637542725
Training time without total dataloading part /epoch 0.014487504959106445
load block tensor time/epoch 0.02754068374633789
block to device time/epoch 0.012707948684692383
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00179 | Loss 1.1757 | Train 0.4772 | Val 0.5204 | Test 0.5466
Number of nodes for computation during this epoch:  491802
Number of first layer input nodes during this epoch:  167726
 full batch blocks save
Number of first layer input nodes during this epoch:  167713
torch.Size([167713, 128])
torch.Size([166679, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.029549360275268555 |0.016515016555786133 |0.00530552864074707 |0.00017380714416503906 |0.0040171146392822266 |0.002817869186401367 |
----------------------------------------------------------pseudo_mini_loss sum 1.1762291193008423
Total dataloading + training time/epoch 1.671917768319448
Training time/epoch 1.3589544296264648
Training time without block to device /epoch 1.3424394130706787
Training time without total dataloading part /epoch 0.012314319610595703
load block tensor time/epoch 0.029549360275268555
block to device time/epoch 0.016515016555786133
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00180 | Loss 1.1762 | Train 0.4774 | Val 0.5208 | Test 0.5465
Number of nodes for computation during this epoch:  491747
Number of first layer input nodes during this epoch:  167713
 full batch blocks save
Number of first layer input nodes during this epoch:  167748
torch.Size([167748, 128])
torch.Size([166714, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.041372060775756836 |0.014135360717773438 |0.004759550094604492 |0.00014734268188476562 |0.004063129425048828 |0.002119302749633789 |
----------------------------------------------------------pseudo_mini_loss sum 1.1715962886810303
Total dataloading + training time/epoch 1.6696644988507856
Training time/epoch 1.263988971710205
Training time without block to device /epoch 1.2498536109924316
Training time without total dataloading part /epoch 0.011089324951171875
load block tensor time/epoch 0.041372060775756836
block to device time/epoch 0.014135360717773438
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00181 | Loss 1.1716 | Train 0.4774 | Val 0.5210 | Test 0.5466
Number of nodes for computation during this epoch:  491792
Number of first layer input nodes during this epoch:  167748
 full batch blocks save
Number of first layer input nodes during this epoch:  167743
torch.Size([167743, 128])
torch.Size([166650, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.028912067413330078 |0.012773275375366211 |0.08841681480407715 |0.00014519691467285156 |0.004178524017333984 |0.002351522445678711 |
----------------------------------------------------------pseudo_mini_loss sum 1.170971393585205
Total dataloading + training time/epoch 1.6673351172562485
Training time/epoch 1.2456333637237549
Training time without block to device /epoch 1.2328600883483887
Training time without total dataloading part /epoch 0.0950920581817627
load block tensor time/epoch 0.028912067413330078
block to device time/epoch 0.012773275375366211
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00182 | Loss 1.1710 | Train 0.4775 | Val 0.5212 | Test 0.5467
Number of nodes for computation during this epoch:  491832
Number of first layer input nodes during this epoch:  167743
 full batch blocks save
Number of first layer input nodes during this epoch:  167765
torch.Size([167765, 128])
torch.Size([166683, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.04748249053955078 |0.04293966293334961 |0.007378816604614258 |0.0021042823791503906 |0.005427837371826172 |0.003361940383911133 |
----------------------------------------------------------pseudo_mini_loss sum 1.1677519083023071
Total dataloading + training time/epoch 1.6661742515251285
Training time/epoch 1.4547948837280273
Training time without block to device /epoch 1.4118552207946777
Training time without total dataloading part /epoch 0.018272876739501953
load block tensor time/epoch 0.04748249053955078
block to device time/epoch 0.04293966293334961
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00183 | Loss 1.1678 | Train 0.4775 | Val 0.5211 | Test 0.5467
Number of nodes for computation during this epoch:  491808
Number of first layer input nodes during this epoch:  167765
 full batch blocks save
Number of first layer input nodes during this epoch:  167721
torch.Size([167721, 128])
torch.Size([166678, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.030541658401489258 |0.020691871643066406 |0.010090827941894531 |0.0003192424774169922 |0.004147052764892578 |0.005671262741088867 |
----------------------------------------------------------pseudo_mini_loss sum 1.168278455734253
Total dataloading + training time/epoch 1.665053367614746
Training time/epoch 1.4598281383514404
Training time without block to device /epoch 1.439136266708374
Training time without total dataloading part /epoch 0.02022838592529297
load block tensor time/epoch 0.030541658401489258
block to device time/epoch 0.020691871643066406
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00184 | Loss 1.1683 | Train 0.4775 | Val 0.5207 | Test 0.5462
Number of nodes for computation during this epoch:  491729
Number of first layer input nodes during this epoch:  167721
 full batch blocks save
Number of first layer input nodes during this epoch:  167715
torch.Size([167715, 128])
torch.Size([166611, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.02912282943725586 |0.012862682342529297 |0.005250692367553711 |0.0001666545867919922 |0.003737211227416992 |0.0029754638671875 |
----------------------------------------------------------pseudo_mini_loss sum 1.1638089418411255
Total dataloading + training time/epoch 1.6633201122283936
Training time/epoch 1.3443105220794678
Training time without block to device /epoch 1.3314478397369385
Training time without total dataloading part /epoch 0.012130022048950195
load block tensor time/epoch 0.02912282943725586
block to device time/epoch 0.012862682342529297
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00185 | Loss 1.1638 | Train 0.4771 | Val 0.5198 | Test 0.5458
Number of nodes for computation during this epoch:  491626
Number of first layer input nodes during this epoch:  167715
 full batch blocks save
Number of first layer input nodes during this epoch:  167750
torch.Size([167750, 128])
torch.Size([166669, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.04332256317138672 |0.01711297035217285 |0.0050275325775146484 |0.00017976760864257812 |0.0045397281646728516 |0.0021839141845703125 |
----------------------------------------------------------pseudo_mini_loss sum 1.1608271598815918
Total dataloading + training time/epoch 1.6616039096668203
Training time/epoch 1.344019889831543
Training time without block to device /epoch 1.3269069194793701
Training time without total dataloading part /epoch 0.01193094253540039
load block tensor time/epoch 0.04332256317138672
block to device time/epoch 0.01711297035217285
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00186 | Loss 1.1608 | Train 0.4764 | Val 0.5190 | Test 0.5450
Number of nodes for computation during this epoch:  491724
Number of first layer input nodes during this epoch:  167750
 full batch blocks save
Number of first layer input nodes during this epoch:  167756
torch.Size([167756, 128])
torch.Size([166688, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.04141569137573242 |0.01940131187438965 |0.006147623062133789 |0.00020194053649902344 |0.004057884216308594 |0.0031538009643554688 |
----------------------------------------------------------pseudo_mini_loss sum 1.1599408388137817
Total dataloading + training time/epoch 1.6607250351319338
Training time/epoch 1.497098445892334
Training time without block to device /epoch 1.4776971340179443
Training time without total dataloading part /epoch 0.013561248779296875
load block tensor time/epoch 0.04141569137573242
block to device time/epoch 0.01940131187438965
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00187 | Loss 1.1599 | Train 0.4759 | Val 0.5183 | Test 0.5446
Number of nodes for computation during this epoch:  491865
Number of first layer input nodes during this epoch:  167756
 full batch blocks save
Number of first layer input nodes during this epoch:  167698
torch.Size([167698, 128])
torch.Size([166647, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.02891087532043457 |0.013162851333618164 |0.005263090133666992 |0.0001728534698486328 |0.0039825439453125 |0.0027556419372558594 |
----------------------------------------------------------pseudo_mini_loss sum 1.1581711769104004
Total dataloading + training time/epoch 1.6589294519830258
Training time/epoch 1.3230657577514648
Training time without block to device /epoch 1.3099029064178467
Training time without total dataloading part /epoch 0.012174129486083984
load block tensor time/epoch 0.02891087532043457
block to device time/epoch 0.013162851333618164
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00188 | Loss 1.1582 | Train 0.4755 | Val 0.5180 | Test 0.5443
Number of nodes for computation during this epoch:  491678
Number of first layer input nodes during this epoch:  167698
 full batch blocks save
Number of first layer input nodes during this epoch:  167772
torch.Size([167772, 128])
torch.Size([166671, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.02913212776184082 |0.012704849243164062 |0.005568504333496094 |0.00019741058349609375 |0.004096508026123047 |0.0028107166290283203 |
----------------------------------------------------------pseudo_mini_loss sum 1.159351110458374
Total dataloading + training time/epoch 1.6572791760560697
Training time/epoch 1.3469367027282715
Training time without block to device /epoch 1.3342318534851074
Training time without total dataloading part /epoch 0.012673139572143555
load block tensor time/epoch 0.02913212776184082
block to device time/epoch 0.012704849243164062
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00189 | Loss 1.1594 | Train 0.4753 | Val 0.5182 | Test 0.5445
Number of nodes for computation during this epoch:  491852
Number of first layer input nodes during this epoch:  167772
 full batch blocks save
Number of first layer input nodes during this epoch:  167761
torch.Size([167761, 128])
torch.Size([166683, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.037192583084106445 |0.05162477493286133 |0.006890773773193359 |0.00019860267639160156 |0.004281759262084961 |0.003271341323852539 |
----------------------------------------------------------pseudo_mini_loss sum 1.1600521802902222
Total dataloading + training time/epoch 1.65597344197725
Training time/epoch 1.4090964794158936
Training time without block to device /epoch 1.3574717044830322
Training time without total dataloading part /epoch 0.014642477035522461
load block tensor time/epoch 0.037192583084106445
block to device time/epoch 0.05162477493286133
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00190 | Loss 1.1601 | Train 0.4754 | Val 0.5188 | Test 0.5447
Number of nodes for computation during this epoch:  491801
Number of first layer input nodes during this epoch:  167761
 full batch blocks save
Number of first layer input nodes during this epoch:  167728
torch.Size([167728, 128])
torch.Size([166660, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.02870488166809082 |0.012103557586669922 |0.005349397659301758 |0.0001800060272216797 |0.004406929016113281 |0.0029959678649902344 |
----------------------------------------------------------pseudo_mini_loss sum 1.1540950536727905
Total dataloading + training time/epoch 1.6615457434928853
Training time/epoch 2.7201950550079346
Training time without block to device /epoch 2.7080914974212646
Training time without total dataloading part /epoch 0.012932300567626953
load block tensor time/epoch 0.02870488166809082
block to device time/epoch 0.012103557586669922
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00191 | Loss 1.1541 | Train 0.4758 | Val 0.5193 | Test 0.5451
Number of nodes for computation during this epoch:  491703
Number of first layer input nodes during this epoch:  167728
 full batch blocks save
Number of first layer input nodes during this epoch:  167734
torch.Size([167734, 128])
torch.Size([166652, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.02852034568786621 |0.012453079223632812 |0.004571199417114258 |0.0001468658447265625 |0.0040667057037353516 |0.0020651817321777344 |
----------------------------------------------------------pseudo_mini_loss sum 1.149580717086792
Total dataloading + training time/epoch 1.6591891882320244
Training time/epoch 1.20900297164917
Training time without block to device /epoch 1.196549892425537
Training time without total dataloading part /epoch 0.010849952697753906
load block tensor time/epoch 0.02852034568786621
block to device time/epoch 0.012453079223632812
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00192 | Loss 1.1496 | Train 0.4761 | Val 0.5194 | Test 0.5451
Number of nodes for computation during this epoch:  491696
Number of first layer input nodes during this epoch:  167734
 full batch blocks save
Number of first layer input nodes during this epoch:  167736
torch.Size([167736, 128])
torch.Size([166662, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.0403597354888916 |0.016613483428955078 |0.004708528518676758 |0.0001480579376220703 |0.004170417785644531 |0.0021677017211914062 |
----------------------------------------------------------pseudo_mini_loss sum 1.1500104665756226
Total dataloading + training time/epoch 1.6579800455063736
Training time/epoch 1.425736427307129
Training time without block to device /epoch 1.4091229438781738
Training time without total dataloading part /epoch 0.011194705963134766
load block tensor time/epoch 0.0403597354888916
block to device time/epoch 0.016613483428955078
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00193 | Loss 1.1500 | Train 0.4762 | Val 0.5199 | Test 0.5452
Number of nodes for computation during this epoch:  491749
Number of first layer input nodes during this epoch:  167736
 full batch blocks save
Number of first layer input nodes during this epoch:  167691
torch.Size([167691, 128])
torch.Size([166672, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.03055882453918457 |0.013198375701904297 |0.0052490234375 |0.0001709461212158203 |0.004231691360473633 |0.0027756690979003906 |
----------------------------------------------------------pseudo_mini_loss sum 1.1469976902008057
Total dataloading + training time/epoch 1.6562143490486538
Training time/epoch 1.3153433799743652
Training time without block to device /epoch 1.302145004272461
Training time without total dataloading part /epoch 0.012427330017089844
load block tensor time/epoch 0.03055882453918457
block to device time/epoch 0.013198375701904297
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00194 | Loss 1.1470 | Train 0.4761 | Val 0.5195 | Test 0.5450
Number of nodes for computation during this epoch:  491712
Number of first layer input nodes during this epoch:  167691
 full batch blocks save
Number of first layer input nodes during this epoch:  167732
torch.Size([167732, 128])
torch.Size([166682, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.02961421012878418 |0.011948823928833008 |0.005258798599243164 |0.00017905235290527344 |0.004076480865478516 |0.0027985572814941406 |
----------------------------------------------------------pseudo_mini_loss sum 1.1477081775665283
Total dataloading + training time/epoch 1.6544753649295905
Training time/epoch 1.317021369934082
Training time without block to device /epoch 1.305072546005249
Training time without total dataloading part /epoch 0.012312889099121094
load block tensor time/epoch 0.02961421012878418
block to device time/epoch 0.011948823928833008
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00195 | Loss 1.1477 | Train 0.4759 | Val 0.5189 | Test 0.5442
Number of nodes for computation during this epoch:  491718
Number of first layer input nodes during this epoch:  167732
 full batch blocks save
Number of first layer input nodes during this epoch:  167723
torch.Size([167723, 128])
torch.Size([166681, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.030194997787475586 |0.01218724250793457 |0.005212306976318359 |0.0001614093780517578 |0.003991603851318359 |0.0028307437896728516 |
----------------------------------------------------------pseudo_mini_loss sum 1.146498441696167
Total dataloading + training time/epoch 1.6527617707544444
Training time/epoch 1.3185226917266846
Training time without block to device /epoch 1.30633544921875
Training time without total dataloading part /epoch 0.012196063995361328
load block tensor time/epoch 0.030194997787475586
block to device time/epoch 0.01218724250793457
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00196 | Loss 1.1465 | Train 0.4757 | Val 0.5182 | Test 0.5437
Number of nodes for computation during this epoch:  491790
Number of first layer input nodes during this epoch:  167723
 full batch blocks save
Number of first layer input nodes during this epoch:  167706
torch.Size([167706, 128])
torch.Size([166638, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.029199600219726562 |0.014690876007080078 |0.005476713180541992 |0.0001766681671142578 |0.004077434539794922 |0.0029914379119873047 |
----------------------------------------------------------pseudo_mini_loss sum 1.1433149576187134
Total dataloading + training time/epoch 1.6514547403693804
Training time/epoch 1.3951871395111084
Training time without block to device /epoch 1.3804962635040283
Training time without total dataloading part /epoch 0.012722253799438477
load block tensor time/epoch 0.029199600219726562
block to device time/epoch 0.014690876007080078
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00197 | Loss 1.1433 | Train 0.4756 | Val 0.5175 | Test 0.5427
Number of nodes for computation during this epoch:  491698
Number of first layer input nodes during this epoch:  167706
 full batch blocks save
Number of first layer input nodes during this epoch:  167699
torch.Size([167699, 128])
torch.Size([166646, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.029810667037963867 |0.015318870544433594 |0.0052416324615478516 |0.00016641616821289062 |0.0040454864501953125 |0.002780914306640625 |
----------------------------------------------------------pseudo_mini_loss sum 1.140364170074463
Total dataloading + training time/epoch 1.6498420635859172
Training time/epoch 1.3320560455322266
Training time without block to device /epoch 1.316737174987793
Training time without total dataloading part /epoch 0.01223444938659668
load block tensor time/epoch 0.029810667037963867
block to device time/epoch 0.015318870544433594
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00198 | Loss 1.1404 | Train 0.4754 | Val 0.5166 | Test 0.5418
Number of nodes for computation during this epoch:  491651
Number of first layer input nodes during this epoch:  167699
 full batch blocks save
Number of first layer input nodes during this epoch:  167757
torch.Size([167757, 128])
torch.Size([166683, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.028158187866210938 |0.013483762741088867 |0.004918813705444336 |0.0001633167266845703 |0.004304170608520508 |0.002164125442504883 |
----------------------------------------------------------pseudo_mini_loss sum 1.1456568241119385
Total dataloading + training time/epoch 1.647989180818874
Training time/epoch 1.2810297012329102
Training time without block to device /epoch 1.2675459384918213
Training time without total dataloading part /epoch 0.011550426483154297
load block tensor time/epoch 0.028158187866210938
block to device time/epoch 0.013483762741088867
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00199 | Loss 1.1457 | Train 0.4749 | Val 0.5160 | Test 0.5409
Number of nodes for computation during this epoch:  491801
Number of first layer input nodes during this epoch:  167757
 full batch blocks save
Number of first layer input nodes during this epoch:  167734
torch.Size([167734, 128])
torch.Size([166663, 256])
times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.028634071350097656 |0.012899637222290039 |0.00466609001159668 |0.0001499652862548828 |0.0041561126708984375 |0.0020933151245117188 |
----------------------------------------------------------pseudo_mini_loss sum 1.142608404159546
Total dataloading + training time/epoch 1.6459164333343506
Training time/epoch 1.2333543300628662
Training time without block to device /epoch 1.2204546928405762
Training time without total dataloading part /epoch 0.011065483093261719
load block tensor time/epoch 0.028634071350097656
block to device time/epoch 0.012899637222290039
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 8.940696716308594e-08
Run 00 | Epoch 00200 | Loss 1.1426 | Train 0.4748 | Val 0.5158 | Test 0.5405
Number of nodes for computation during this epoch:  491690
Number of first layer input nodes during this epoch:  167734
Run 01:
Highest Train: 47.75
Highest Valid: 52.37
  Final Train: 47.74
   Final Test: 54.96
All runs:
Highest Train: 47.75  nan
Highest Valid: 52.37  nan
  Final Train: 47.74  nan
   Final Test: 54.96  nan
GraphSAGE(
  (layers): ModuleList(
    (0): SAGEConv(
      (feat_drop): Dropout(p=0.0, inplace=False)
      (fc_self): Linear(in_features=128, out_features=256, bias=False)
      (fc_neigh): Linear(in_features=128, out_features=256, bias=False)
    )
    (1): SAGEConv(
      (feat_drop): Dropout(p=0.0, inplace=False)
      (fc_self): Linear(in_features=256, out_features=256, bias=False)
      (fc_neigh): Linear(in_features=256, out_features=256, bias=False)
    )
    (2): SAGEConv(
      (feat_drop): Dropout(p=0.0, inplace=False)
      (fc_self): Linear(in_features=256, out_features=40, bias=False)
      (fc_neigh): Linear(in_features=256, out_features=40, bias=False)
    )
  )
  (bns): ModuleList(
    (0): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropout): Dropout(p=0.3, inplace=False)
)
total model parameters size  218112
trainable parameters
layers.0.fc_self.weight, torch.Size([256, 128])
layers.0.fc_neigh.weight, torch.Size([256, 128])
layers.1.fc_self.weight, torch.Size([256, 256])
layers.1.fc_neigh.weight, torch.Size([256, 256])
layers.2.fc_self.weight, torch.Size([40, 256])
layers.2.fc_neigh.weight, torch.Size([40, 256])
bns.0.weight, torch.Size([256])
bns.0.bias, torch.Size([256])
bns.1.weight, torch.Size([256])
bns.1.bias, torch.Size([256])
----------------------------------------
un-trainable parameters
